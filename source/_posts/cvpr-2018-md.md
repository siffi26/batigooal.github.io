---
title: CVPR2018论文整理
date: 2018-06-13 13:45:23
categories: 资料汇总
tags:
     - resources
---
##### Learning Pixel-level Semantic Affinity with Image-level Supervision for Weakly Supervised Semantic Segmentation

关键词：弱监督训练，语义分割

摘要：为了解决分割标签制作的低效率问题，文章提出了一个新的框架，**根据图像级别的类别标签生成图像的语义标签**。在这种弱监督环境中，我们知道训练过的模型可以分割局部区域而不是整个物体区域。我们的方法是将这种本地响应传播到属于同一语义整体的相邻区域。为此，我们提出一个叫做AffinityNet的深度神经网络用于预测一对相邻图像坐标之间的语义亲和度。然后，通过AffinityNet预测亲和性随机游走来实现语义传播。更重要的是，用来训练AffinityNet的监督信号是由初始判别性部分分割给出的，它作为分割标注来说是不完全的，但是足够学习小图像区域内的语义亲和度。因此，整个框架仅仅依赖于图像级的类别标注，并不需要额外数据或标注。在VOC2012数据集上，使用我们方法生成的分割标注学习的DNN效果优于之前用相同监督水平训练的模型，甚至与那些依赖强监督的模型相比也是具有竞争力的。

##### A PID Controller Approach for Stochastic Optimization of Deep Networks

可读性：★★★

关键词：训练优化方法，PID控制

摘要：深度神经网络已经在许多计算机视觉应用中证明了它们的能力，如VGG，ResNet和DenseNet之类的最先进的模型主要通过SGD-Momentum算法进行优化，该算法通过考虑过去和当前的梯度来更新权重。尽管如此，**SGD-Momentum仍存在超调问题**，阻碍了网络训练的融合。受自动控制中PID控制器成功的启发，我们提出了一种用于加速深度网络优化的PID方法。我们首先揭示了SGD-Momentum和基于PID的控制器之间的内在联系，然后介绍利用过去，当前和梯度变化来更新网络参数的优化算法。**所提出的PID方法大大减少了SGD-Momentum的过冲现象**，并且通过我们对基准数据集（包括CIFAR10，CIFAR100和Tiny-ImageNet）的实验验证，它可以在具有竞争精度的DNN架构上实现高达50％的加速。

代码：[PIDOptimizer](https://github.com/tensorboy/PIDOptimizer)

备注：PID控制的思想引入到模型训练的随机优化过程，据说效果不错，但是主要优点在与可以加速训练收敛的速度，有空可以自己跑一下代码试试。

##### Finding Tiny Faces in the Wild with Generative Adversarial Network

关键词：人脸检测，生成对抗网络

摘要：人脸检测技术已经发展了数十年，其中一个尚未解决的挑战是**在无约束的条件下检测小脸**。原因是**微小的脸部往往缺乏详细的信息和模糊**。在本文中，我们提出了一种算法，通过采用生成对抗网络（GAN），从模糊的小模型直接生成清晰的高分辨率人脸。基本的GAN通过超分辨率和精细化（例如SR-GAN和cycle-GAN）来实现。但是，我们设计了一个新颖的网络来解决超解决和共同提炼的问题。我们还引入了新的训练损失，以指导发生器网络恢复细节，并促使鉴别器网络同时区分真假和脸部/非脸部。在具有挑战性的数据集WIDER FACE上进行的大量实验证明我们提出的方法能够从一个模糊的小图像恢复清晰的高分辨率人脸，并显示其检测性能优于其他最先进的方法。

##### The power of ensembles for active learning in image classification

可读性：★★

关键词：主动学习

摘要：深度学习方法已成为挑战图像处理任务（如图像分类）的事实标准。深度学习方法的一个主要障碍是需要大量的标记数据，这可能会导致昂贵的成本，特别是在医学图像诊断应用中。**主动学习技术**可以缓解这种标签工作。在本文中，我们研究一些最近提出的用于高维数据和卷积神经网络分类器的主动学习方法。我们比较了基于集合的方法与蒙特卡洛压差和几何方法。我们发现集成表现更好，并导致更多校准的预测不确定性，这是许多主动学习算法的基础。为了调查为什么蒙特卡罗辍学不确定性表现更差，我们在一系列实验中探索了孤立性的潜在差异。我们展示了MNIST和CIFAR-10的结果，其中我们用大约12,200个标记图像获得了90％的测试集精度，并在ImageNet上获得了初始结果。此外，我们在大型高度不平衡的糖尿病性视网膜病变数据集上展示结果。我们观察到，基于集成的主动学习方法有效地抵消了不平衡的影响。

备注：介绍了主动学习和集成学习相结合的方法。

##### Dense Decoder Shortcut Connections for Single-Pass Semantic Segmentation

可读性：★★

关键词：语义分割，Dense Decoder

摘要：我们提出了一种**用于单通道语义分割的新型端到端可训练深度编码器解码器架构**。我们的方法基于具有功能级远程跳过连接的级联架构。该编码器结合了ResNeXt残差构建模块的结构，并采用重复构建模块的策略，该构建模块汇总了具有相同拓扑的一组变换。该解码器具有一种新颖的架构，由块组成，这些架构包括（i）捕获上下文信息，（ii）生成语义特征，以及（iii）实现不同输出分辨率之间的融合。至关重要的是，我们引入了密集的解码器快捷连接，以允许解码器块使用来自所有先前解码器级别的语义特征映射，即来自所有更高级别的特征映射。密集的解码器连接允许从一个解码器块到另一个解码器块的有效信息传播，以及多级特征融合，从而显着提高准确性。重要的是，这些连接使我们的方法能够在几个具有挑战性的数据集上获得最先进的性能，而不需要之前多尺度工作那样的平均耗时。

##### Cascade R-CNN: Delving into High Quality Object Detection

可读性：★★★★★

关键词：级联R-CNN，目标检测

摘要：在目标检测中，需要通过IoU阈值来定义正例和负例。用低IoU阈值进行训练的目标检测器，如0.5，通常会产生嘈杂的检测结果。但是，**IoU阈值增加后检测性能会降低**。造成这种情况的原因有两个：1）正样本太少会导致训练过拟合；2）推理时间不匹配。本文提出了级联检测算法Cascade R-CNN用于解决这些问题。它由一系列IoU阈值增加而训练的检测器组成，以对接近的假阳性依次更具有选择性。目标检测器逐步进行训练，利用观测器的输出是一个良好的分布来训练下一个更高质量的目标检测器。逐步改进假设的重采样从而保证所有目标检测器都有一组正确的等效大小样本，减少过拟合的情况。在部署中应用相同的级联结构，使得假设和每个阶段的目标检测器质量之间更接近匹配。级联R-CNN的简单实现超过COCO数据集上所有单模型目标检测器。实验还表明，级联R-CNN可广泛应用于不同的目标检测器架构，获得与基准检测器强度无关的一致增益。

代码：[Cascade R-CNN](https://github.com/zhaoweicai/cascade-rcnn)

备注：R-CNN的级联结构，应该是高分辨率图像中目标检测算法的趋势。

##### Deep Cauchy Hashing for Hamming Space Retrieval

关键词：图像检索，哈希编码

摘要：哈希算法由于其计算效率和检索质量，已被广泛应用于近似最近邻搜索的大规模图像检索，而深度哈希通过端到端表示学习和哈希编码进一步提高了检索质量。通过紧凑的散列码，海明空间检索可实现最有效的恒定时间搜索，该搜索可通过散列表查找而不是线性扫描将给定汉明半径内的数据点返回给每个查询。然而，由于错误指定的损失函数，将相关图像集中在小海明球内的能力较弱，现有的深度哈希方法可能会因海明空间检索而表现不佳。这项工作提出了Deep Cauchy Hashing（DCH），这是一种新颖的深度哈希模型，可生成紧凑且集中的二进制哈希代码，从而实现高效的海明空间检索。其主要思想是设计一个基于柯西分布的成对交叉熵损失，在海明距离大于给定的汉明半径阈值的情况下，对相似图像对产生显著的惩罚。综合实验表明，DCH可以生成高度集中的散列码，并在三个数据集NUS-WIDE，CIFAR-10和MS-COCO上产生最先进的海明空间检索性能。

##### HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN

关键词：图像检索，哈希编码

摘要：深度哈希通过端对端表示学习和来自具有成对相似性信息的训练数据的哈希编码来改善图像检索性能。由于相似性信息的稀缺性对于许多应用领域来说通常很昂贵，所以现有的对哈希方法的深度学习可能过度训练数据并导致检索质量的显著损失。本文介绍了HashGAN，一种用于深入学习哈希的新颖体系结构，它从真实图像和由生成模型合成的各种图像学习紧凑二进制哈希码。其主要思想是增加训练数据，用几乎真实的图像合成一个新的Pair Conditional Wasserstein GAN（PC-WGAN）条件成对相似性信息。大量实验表明，HashGAN可以生成高质量的二进制散列码，并在NUS-WIDE，CIFAR-10和MS-COCO三个基准测试中获得最先进的图像检索性能。

##### Partially Shared Multi-Task Convolutional Neural Network with Local Constraint for Face Attribute Learning

可读性：★★★

关键词：人脸属性识别

摘要：在本文中，我们同时考虑身份信息和属性关系来研究人脸属性的学习问题。具体而言，我们首先引入部分共享多任务卷积神经网络（PS-MCNN），其中四个任务专用网络（TSNets）和一个共享网络（SNet）通过部分共享（PS）结构连接以学习更好的共享和任务特定的表示。为了利用身份信息来进一步提高性能，我们引入了局部学习约束，该约束将每个样本与其具有相同身份的局部几何领域的表示之间的差异最小化。因此，我们提出了一个局部约束正规化的多任务网络，称为局部共享多任务卷积神经网络与局部约束（PS-MCNNLC），其中PS结构和局部约束集成在一起，以帮助框架学习更好的属性表示。CelebA和LFWA的实验结果证明了所提出方法的前景

##### Pose-Robust Face Recognition via Deep Residual Equivariant Mapping

可读性：★★★★★

关键词：人脸识别

摘要：由于深度学习的出现，人脸识别取得了非凡的成功。然而，与正面相比，许多当代人脸识别模型在处理人脸时仍然表现较差。**一个关键的原因是正面和侧面训练面孔的数量高度不平衡**。与侧面训练样本相比，正面训练样本更多。此外，从本质上来说，**很难学习一个对于大姿态变化下具有几何不变性的深度表示**。在本研究中，我们假设前面和侧面之间存在固有的映射关系，因此它们在深度表示空间中的差异可以通过等变映射来弥补。为了利用这种映射，我们制定了一种新颖的深度残差等熵映射（DREAM）块，它能够自适应地将残差添加到输入深度表示中，**以将剖面人脸表示转换为简化识别的典型姿态**。DREAM模块不断加强许多强大深度网络（包括ResNet模型）的轮廓人脸识别性能，而不会有意增加轮廓面的训练数据。该模块易于使用，重量轻，并且可以用可忽略的计算开销1来实现。

代码：[DREAM](https://github.com/penincillin/DREAM)

备注：[中文解读](http://www.sohu.com/a/225437836_129720)

##### “Learning-Compression” Algorithms for Neural Net Pruning

可读性：★★★

关键词：剪枝，模型压缩，模型优化

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

##### Deep Spatio-Temporal Random Fields for Efficient Video Segmentation

可读性：★★

关键词：视频分割

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

代码：[gcrf](https://github.com/siddharthachandra/gcrf)

##### Multi-Level Factorisation Net for Person Re-Identification

可读性：★★★★

关键词：行人再识别

摘要：有效的行人再识别（Re-ID）的关键是**在高和低的语义层次上对行人外观的区别性和视角不变因素进行建模**。最近开发的深度Re-ID模型**要么学习整体单一语义级别的特征表示和/或需要这些因素的费力的人类注释作为属性**。我们提出了**多层次因子网（MLFN）**，这是一种新颖的网络架构，可将人的视觉外观在多种语义层次上分解为潜在的判别因子，无需人工注释。MLFN由多个堆叠块组成。每个块包含多个因子模块以模拟特定级别的潜在因子，因子选择模块动态选择因子模块以解释每个输入图像的内容。因子选择模块的输出还提供了一个紧凑的潜在因子描述符，它与传统的深度学习特征相辅相成。MLFN在三个Re-ID数据集上实现了最先进的结果，并在通用对象分类CIFAR-100数据集上获得了令人瞩目的结果。

##### Pyramid Stereo Matching Network

可读性：★★★

关键词：双目深度估计

摘要：最近的研究表明，从一对立体图像进行深度估计可以被制定为一个监督学习任务，用卷积神经网络（CNN）来解决。然而，目前的体系结构依赖于基于补丁的连体网络，缺乏利用上下文信息来找到在所示区域的对应关系的手段。为了解决这个问题，我们提出PSMNet，一个由两个主要模块组成的金字塔立体匹配网络：空间金字塔池和3D-CNN。空间金字塔池模块通过聚合不同尺度和位置的上下文来利用全局上下文信息的能力来调整惩罚量。3D-CNN学习使用堆叠的多个沙漏网络结合中间监督来调整惩罚量。所提出的方法在几个基准数据集上进行了评估。 我们的方法在2018年3月18日之前的KITTI 2012和2015排行榜中排名第一。

代码：[PSMNet](https://github.com/JiaRenChang/PSMNet)

##### Cascaded Pyramid Network for Multi-Person Pose Estimation

可读性：★

关键词：多人姿态估计，关键点检测

摘要：多人姿态估计近年来得到了很大的改善，特别是随着卷积神经网络的发展。然而，仍然存在很多具有挑战性的案例，例如**闭塞的关键点，不可见的关键点和复杂的背景**，这些都不能很好地解决。在本文中，我们提出了一种称为级联金字塔网络（CPN）的新型网络结构，其目标是从这些“硬”关键点解决问题。更具体地说，我们的算法包括两个阶段：GlobalNet和RefineNet。GlobalNet是一个功能金字塔网络，可以成功定位像眼睛和手这样的“简单”关键点，但可能无法准确识别被遮挡或不可见的关键点。我们的RefineNet试图通过集成GlobalNet的所有级别的特征表示以及在线硬关键点挖掘损失来明确处理“硬”关键点。通常，为了解决多人姿态估计问题，采用自顶向下的管线首先根据检测器生成一组人类边界框，然后在每个人体边界框中用CPN进行关键点定位。基于所提出的算法，我们在COCO关键点基准测试中获得了最先进的结果，COCO测试开发数据集的平均精度为73.0，COCO测试挑战数据集的平均精度为72.1，与60.5相比，相对提高了19％来自COCO 2016关键挑战。 Code1以及所使用人员的检测结果将公开发布供进一步研究。

代码：[CPN](https://github.com/chenyilun95/tf-cpn)

##### Deep Hashing via Discrepancy Minimization

关键词：哈希编码，图像检索

摘要：本文提出了一个差异最小化模型来解决**哈希学习中的离散优化问题**。二元约束引入的离散优化是一个NP难混合整数规划问题。通常通过将二进制变量放宽为连续变量来适应基于梯度的哈希函数学习，特别是深度神经网络的训练。针对松弛引起的客观差异，将原始二元优化问题转化为哈希函数可微分优化问题。该变换将二进制约束和相似性保持散列函数优化解耦。转换后的目标在一个易处理的交替优化框架中进行了优化，并逐步减少了差异。在三个基准数据集上的广泛实验结果验证了所提出的差异使散列最小化的有效性。

##### Group Consistent Similarity Learning via Deep CRF for Person Re-Identification

可读性：★★★

关键词：行人再识别

摘要：行人再识别从深度神经网络（DNN）中获益很多，以学习精确的相似性度量和强健的特征嵌入。然而，目前大多数方法仅对相似性学习施加局部约束。在本文中，我们将CRF与深度神经网络相结合，将大型图像组的约束纳入其中。所提出的方法旨在学习成对图像的“局部相似性”度量，同时考虑组中所有图像的相关性，形成“组相似性”。我们的方法涉及多个图像来模拟训练期间统一CRF中局部和全局相似性之间的关系，同时结合多尺度局部相似性作为测试中的预测相似性。我们采用近似推理方案来估计组相似性，从而实现端到端的培训。大量的实验证明了我们的模型的有效性，它结合了DNN和CRF来学习稳健的多尺度局部相似性。整体结果优于那些在三个广泛使用的基准上具有相当利润率的艺术家。
