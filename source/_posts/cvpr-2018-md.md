---
title: CVPR2018论文整理
date: 2018-06-13 13:45:23
categories: 资料汇总
tags:
     - resources
---
##### Learning Pixel-level Semantic Affinity with Image-level Supervision for Weakly Supervised Semantic Segmentation

关键词：弱监督训练，语义分割

摘要：为了解决分割标签制作的低效率问题，文章提出了一个新的框架，**根据图像级别的类别标签生成图像的语义标签**。在这种弱监督环境中，我们知道训练过的模型可以分割局部区域而不是整个物体区域。我们的方法是将这种本地响应传播到属于同一语义整体的相邻区域。为此，我们提出一个叫做AffinityNet的深度神经网络用于预测一对相邻图像坐标之间的语义亲和度。然后，通过AffinityNet预测亲和性随机游走来实现语义传播。更重要的是，用来训练AffinityNet的监督信号是由初始判别性部分分割给出的，它作为分割标注来说是不完全的，但是足够学习小图像区域内的语义亲和度。因此，整个框架仅仅依赖于图像级的类别标注，并不需要额外数据或标注。在VOC2012数据集上，使用我们方法生成的分割标注学习的DNN效果优于之前用相同监督水平训练的模型，甚至与那些依赖强监督的模型相比也是具有竞争力的。

##### A PID Controller Approach for Stochastic Optimization of Deep Networks

可读性：★★★

关键词：训练优化方法，PID控制

摘要：深度神经网络已经在许多计算机视觉应用中证明了它们的能力，如VGG，ResNet和DenseNet之类的最先进的模型主要通过SGD-Momentum算法进行优化，该算法通过考虑过去和当前的梯度来更新权重。尽管如此，**SGD-Momentum仍存在超调问题**，阻碍了网络训练的融合。受自动控制中PID控制器成功的启发，我们提出了一种用于加速深度网络优化的PID方法。我们首先揭示了SGD-Momentum和基于PID的控制器之间的内在联系，然后介绍利用过去，当前和梯度变化来更新网络参数的优化算法。**所提出的PID方法大大减少了SGD-Momentum的过冲现象**，并且通过我们对基准数据集（包括CIFAR10，CIFAR100和Tiny-ImageNet）的实验验证，它可以在具有竞争精度的DNN架构上实现高达50％的加速。

代码：[PIDOptimizer](https://github.com/tensorboy/PIDOptimizer)

备注：PID控制的思想引入到模型训练的随机优化过程，据说效果不错，但是主要优点在与可以加速训练收敛的速度，有空可以自己跑一下代码试试。

##### Finding Tiny Faces in the Wild with Generative Adversarial Network

关键词：人脸检测，生成对抗网络

摘要：人脸检测技术已经发展了数十年，其中一个尚未解决的挑战是**在无约束的条件下检测小脸**。原因是**微小的脸部往往缺乏详细的信息和模糊**。在本文中，我们提出了一种算法，通过采用生成对抗网络（GAN），从模糊的小模型直接生成清晰的高分辨率人脸。基本的GAN通过超分辨率和精细化（例如SR-GAN和cycle-GAN）来实现。但是，我们设计了一个新颖的网络来解决超解决和共同提炼的问题。我们还引入了新的训练损失，以指导发生器网络恢复细节，并促使鉴别器网络同时区分真假和脸部/非脸部。在具有挑战性的数据集WIDER FACE上进行的大量实验证明我们提出的方法能够从一个模糊的小图像恢复清晰的高分辨率人脸，并显示其检测性能优于其他最先进的方法。

##### The power of ensembles for active learning in image classification

可读性：★★

关键词：主动学习

摘要：深度学习方法已成为挑战图像处理任务（如图像分类）的事实标准。深度学习方法的一个主要障碍是需要大量的标记数据，这可能会导致昂贵的成本，特别是在医学图像诊断应用中。**主动学习技术**可以缓解这种标签工作。在本文中，我们研究一些最近提出的用于高维数据和卷积神经网络分类器的主动学习方法。我们比较了基于集合的方法与蒙特卡洛压差和几何方法。我们发现集成表现更好，并导致更多校准的预测不确定性，这是许多主动学习算法的基础。为了调查为什么蒙特卡罗辍学不确定性表现更差，我们在一系列实验中探索了孤立性的潜在差异。我们展示了MNIST和CIFAR-10的结果，其中我们用大约12,200个标记图像获得了90％的测试集精度，并在ImageNet上获得了初始结果。此外，我们在大型高度不平衡的糖尿病性视网膜病变数据集上展示结果。我们观察到，基于集成的主动学习方法有效地抵消了不平衡的影响。

备注：介绍了主动学习和集成学习相结合的方法。

##### Dense Decoder Shortcut Connections for Single-Pass Semantic Segmentation

可读性：★★

关键词：语义分割，Dense Decoder

摘要：我们提出了一种**用于单通道语义分割的新型端到端可训练深度编码器解码器架构**。我们的方法基于具有功能级远程跳过连接的级联架构。该编码器结合了ResNeXt残差构建模块的结构，并采用重复构建模块的策略，该构建模块汇总了具有相同拓扑的一组变换。该解码器具有一种新颖的架构，由块组成，这些架构包括（i）捕获上下文信息，（ii）生成语义特征，以及（iii）实现不同输出分辨率之间的融合。至关重要的是，我们引入了密集的解码器快捷连接，以允许解码器块使用来自所有先前解码器级别的语义特征映射，即来自所有更高级别的特征映射。密集的解码器连接允许从一个解码器块到另一个解码器块的有效信息传播，以及多级特征融合，从而显着提高准确性。重要的是，这些连接使我们的方法能够在几个具有挑战性的数据集上获得最先进的性能，而不需要之前多尺度工作那样的平均耗时。

##### Cascade R-CNN: Delving into High Quality Object Detection

可读性：★★★★★

关键词：级联R-CNN，目标检测

摘要：在目标检测中，需要通过IoU阈值来定义正例和负例。用低IoU阈值进行训练的目标检测器，如0.5，通常会产生嘈杂的检测结果。但是，**IoU阈值增加后检测性能会降低**。造成这种情况的原因有两个：1）正样本太少会导致训练过拟合；2）推理时间不匹配。本文提出了级联检测算法Cascade R-CNN用于解决这些问题。它由一系列IoU阈值增加而训练的检测器组成，以对接近的假阳性依次更具有选择性。目标检测器逐步进行训练，利用观测器的输出是一个良好的分布来训练下一个更高质量的目标检测器。逐步改进假设的重采样从而保证所有目标检测器都有一组正确的等效大小样本，减少过拟合的情况。在部署中应用相同的级联结构，使得假设和每个阶段的目标检测器质量之间更接近匹配。级联R-CNN的简单实现超过COCO数据集上所有单模型目标检测器。实验还表明，级联R-CNN可广泛应用于不同的目标检测器架构，获得与基准检测器强度无关的一致增益。

代码：[Cascade R-CNN](https://github.com/zhaoweicai/cascade-rcnn)

备注：R-CNN的级联结构，应该是高分辨率图像中目标检测算法的趋势。

##### Deep Cauchy Hashing for Hamming Space Retrieval

关键词：图像检索，哈希编码

摘要：哈希算法由于其计算效率和检索质量，已被广泛应用于近似最近邻搜索的大规模图像检索，而深度哈希通过端到端表示学习和哈希编码进一步提高了检索质量。通过紧凑的散列码，海明空间检索可实现最有效的恒定时间搜索，该搜索可通过散列表查找而不是线性扫描将给定汉明半径内的数据点返回给每个查询。然而，由于错误指定的损失函数，将相关图像集中在小海明球内的能力较弱，现有的深度哈希方法可能会因海明空间检索而表现不佳。这项工作提出了Deep Cauchy Hashing（DCH），这是一种新颖的深度哈希模型，可生成紧凑且集中的二进制哈希代码，从而实现高效的海明空间检索。其主要思想是设计一个基于柯西分布的成对交叉熵损失，在海明距离大于给定的汉明半径阈值的情况下，对相似图像对产生显著的惩罚。综合实验表明，DCH可以生成高度集中的散列码，并在三个数据集NUS-WIDE，CIFAR-10和MS-COCO上产生最先进的海明空间检索性能。

##### HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN

关键词：图像检索，哈希编码

摘要：深度哈希通过端对端表示学习和来自具有成对相似性信息的训练数据的哈希编码来改善图像检索性能。由于相似性信息的稀缺性对于许多应用领域来说通常很昂贵，所以现有的对哈希方法的深度学习可能过度训练数据并导致检索质量的显著损失。本文介绍了HashGAN，一种用于深入学习哈希的新颖体系结构，它从真实图像和由生成模型合成的各种图像学习紧凑二进制哈希码。其主要思想是增加训练数据，用几乎真实的图像合成一个新的Pair Conditional Wasserstein GAN（PC-WGAN）条件成对相似性信息。大量实验表明，HashGAN可以生成高质量的二进制散列码，并在NUS-WIDE，CIFAR-10和MS-COCO三个基准测试中获得最先进的图像检索性能。

##### Partially Shared Multi-Task Convolutional Neural Network with Local Constraint for Face Attribute Learning

可读性：★★★

关键词：人脸属性识别

摘要：在本文中，我们同时考虑身份信息和属性关系来研究人脸属性的学习问题。具体而言，我们首先引入部分共享多任务卷积神经网络（PS-MCNN），其中四个任务专用网络（TSNets）和一个共享网络（SNet）通过部分共享（PS）结构连接以学习更好的共享和任务特定的表示。为了利用身份信息来进一步提高性能，我们引入了局部学习约束，该约束将每个样本与其具有相同身份的局部几何领域的表示之间的差异最小化。因此，我们提出了一个局部约束正规化的多任务网络，称为局部共享多任务卷积神经网络与局部约束（PS-MCNNLC），其中PS结构和局部约束集成在一起，以帮助框架学习更好的属性表示。CelebA和LFWA的实验结果证明了所提出方法的前景

##### Pose-Robust Face Recognition via Deep Residual Equivariant Mapping

可读性：★★★★★

关键词：人脸识别

摘要：由于深度学习的出现，人脸识别取得了非凡的成功。然而，与正面相比，许多当代人脸识别模型在处理人脸时仍然表现较差。**一个关键的原因是正面和侧面训练面孔的数量高度不平衡**。与侧面训练样本相比，正面训练样本更多。此外，从本质上来说，**很难学习一个对于大姿态变化下具有几何不变性的深度表示**。在本研究中，我们假设前面和侧面之间存在固有的映射关系，因此它们在深度表示空间中的差异可以通过等变映射来弥补。为了利用这种映射，我们制定了一种新颖的深度残差等熵映射（DREAM）块，它能够自适应地将残差添加到输入深度表示中，**以将剖面人脸表示转换为简化识别的典型姿态**。DREAM模块不断加强许多强大深度网络（包括ResNet模型）的轮廓人脸识别性能，而不会有意增加轮廓面的训练数据。该模块易于使用，重量轻，并且可以用可忽略的计算开销1来实现。

代码：[DREAM](https://github.com/penincillin/DREAM)

备注：[中文解读](http://www.sohu.com/a/225437836_129720)

##### “Learning-Compression” Algorithms for Neural Net Pruning

可读性：★★★

关键词：剪枝，模型压缩，模型优化

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

##### Deep Spatio-Temporal Random Fields for Efficient Video Segmentation

可读性：★★

关键词：视频分割

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

代码：[gcrf](https://github.com/siddharthachandra/gcrf)

##### Multi-Level Factorisation Net for Person Re-Identification

可读性：★★★★

关键词：行人再识别

摘要：有效的行人再识别（Re-ID）的关键是**在高和低的语义层次上对行人外观的区别性和视角不变因素进行建模**。最近开发的深度Re-ID模型**要么学习整体单一语义级别的特征表示和/或需要这些因素的费力的人类注释作为属性**。我们提出了**多层次因子网（MLFN）**，这是一种新颖的网络架构，可将人的视觉外观在多种语义层次上分解为潜在的判别因子，无需人工注释。MLFN由多个堆叠块组成。每个块包含多个因子模块以模拟特定级别的潜在因子，因子选择模块动态选择因子模块以解释每个输入图像的内容。因子选择模块的输出还提供了一个紧凑的潜在因子描述符，它与传统的深度学习特征相辅相成。MLFN在三个Re-ID数据集上实现了最先进的结果，并在通用对象分类CIFAR-100数据集上获得了令人瞩目的结果。

##### Pyramid Stereo Matching Network

可读性：★★★

关键词：双目深度估计

摘要：最近的研究表明，从一对立体图像进行深度估计可以被制定为一个监督学习任务，用卷积神经网络（CNN）来解决。然而，目前的体系结构依赖于基于补丁的连体网络，缺乏利用上下文信息来找到在所示区域的对应关系的手段。为了解决这个问题，我们提出PSMNet，一个由两个主要模块组成的金字塔立体匹配网络：空间金字塔池和3D-CNN。空间金字塔池模块通过聚合不同尺度和位置的上下文来利用全局上下文信息的能力来调整惩罚量。3D-CNN学习使用堆叠的多个沙漏网络结合中间监督来调整惩罚量。所提出的方法在几个基准数据集上进行了评估。 我们的方法在2018年3月18日之前的KITTI 2012和2015排行榜中排名第一。

代码：[PSMNet](https://github.com/JiaRenChang/PSMNet)

##### Cascaded Pyramid Network for Multi-Person Pose Estimation

可读性：★

关键词：多人姿态估计，关键点检测

摘要：多人姿态估计近年来得到了很大的改善，特别是随着卷积神经网络的发展。然而，仍然存在很多具有挑战性的案例，例如**闭塞的关键点，不可见的关键点和复杂的背景**，这些都不能很好地解决。在本文中，我们提出了一种称为级联金字塔网络（CPN）的新型网络结构，其目标是从这些“硬”关键点解决问题。更具体地说，我们的算法包括两个阶段：GlobalNet和RefineNet。GlobalNet是一个功能金字塔网络，可以成功定位像眼睛和手这样的“简单”关键点，但可能无法准确识别被遮挡或不可见的关键点。我们的RefineNet试图通过集成GlobalNet的所有级别的特征表示以及在线硬关键点挖掘损失来明确处理“硬”关键点。通常，为了解决多人姿态估计问题，采用自顶向下的管线首先根据检测器生成一组人类边界框，然后在每个人体边界框中用CPN进行关键点定位。基于所提出的算法，我们在COCO关键点基准测试中获得了最先进的结果，COCO测试开发数据集的平均精度为73.0，COCO测试挑战数据集的平均精度为72.1，与60.5相比，相对提高了19％来自COCO 2016关键挑战。 Code1以及所使用人员的检测结果将公开发布供进一步研究。

代码：[CPN](https://github.com/chenyilun95/tf-cpn)

##### Deep Hashing via Discrepancy Minimization

关键词：哈希编码，图像检索

摘要：本文提出了一个差异最小化模型来解决**哈希学习中的离散优化问题**。二元约束引入的离散优化是一个NP难混合整数规划问题。通常通过将二进制变量放宽为连续变量来适应基于梯度的哈希函数学习，特别是深度神经网络的训练。针对松弛引起的客观差异，将原始二元优化问题转化为哈希函数可微分优化问题。该变换将二进制约束和相似性保持散列函数优化解耦。转换后的目标在一个易处理的交替优化框架中进行了优化，并逐步减少了差异。在三个基准数据集上的广泛实验结果验证了所提出的差异使散列最小化的有效性。

##### Group Consistent Similarity Learning via Deep CRF for Person Re-Identification

可读性：★★★

关键词：行人再识别

摘要：行人再识别从深度神经网络（DNN）中获益很多，以学习精确的相似性度量和强健的特征嵌入。然而，目前大多数方法仅对相似性学习施加局部约束。在本文中，我们将CRF与深度神经网络相结合，将大型图像组的约束纳入其中。所提出的方法旨在学习成对图像的“局部相似性”度量，同时考虑组中所有图像的相关性，形成“组相似性”。我们的方法涉及多个图像来模拟训练期间统一CRF中局部和全局相似性之间的关系，同时结合多尺度局部相似性作为测试中的预测相似性。我们采用近似推理方案来估计组相似性，从而实现端到端的培训。大量的实验证明了我们的模型的有效性，它结合了DNN和CRF来学习稳健的多尺度局部相似性。整体结果优于那些在三个广泛使用的基准上具有相当利润率的艺术家。

##### MaskLab: Instance Segmentation by Refining Object Detection with Semantic and Direction Features

可读性：★

关键词：实例分割

摘要：在这项工作中，我们解决了实例分割的问题，同时解决了对象检测和语义分割的任务。为了实现这个目标，我们提出了一个名为MaskLab的模型，它产生三个输出：box检测，语义分割和方向预测。建立在Faster-RCNN对象检测器之上，预测框提供了对象实例的精确定位。在每个感兴趣的区域内，MaskLab通过结合语义和方向预测来执行前景/背景分割。语义分割帮助模型区分包括背景在内的不同语义类别的对象，而方向预测（估计每个像素朝向其相应中心的方向）允许分离相同语义类别的实例。此外，我们还探讨了从分段和检测（例如，卷积和超列）中整合最新成功方法的效果。我们提出的模型在COCO实例细分基准上进行评估，并与其他最先进的模型进行比较。

##### Progressively Complementarity-aware Fusion Network for RGB-D Salient Object Detection 

可读性：★★★★

关键词：RGB-D，深度摄像头，目标检测

摘要：**如何充分结合跨模式互补是RGB-D显著物体检测的基石问题**。以前的作品主要通过简单地连接多模态特征或结合单峰预测来解决这个问题。在本文中，我们从两个角度回答了这个问题：（1）我们认为，如果互补部分可以更明确地建模，那么跨模态补充可能会被更好地捕获。为此，我们在采用卷积神经网络（CNN）时设计了一种新型互补感知融合（CA-Fuse）模块。通过在每个CA-Fuse模块中引入交叉模态残差函数和互补意识监督，从成对模态中学习补充信息的问题被明确提出为渐近逼近残差函数。（2）探索各个层面的补充。通过级联CA-Fuse模块并添加从深层到深层的层级式监管，可以选择并逐步组合跨层次补充。所提出的RGB-D融合网络消除了跨模态和跨层次融合过程的歧义，并能够获得更充分的融合结果。公共数据集上的实验显示了所提出的CA-Fuse模块和RGB-D显着物体检测网络的有效性。

##### Optimizing Video Object Detection via a Scale-Time Lattice

可读性：★★★

关键词：视频目标检测

摘要：高性能对象检测依赖于昂贵的卷积网络来计算特征，这经常导致应用中的重大挑战，例如，那些需要实时从视频流中检测对象的应用程序。这个问题的关键是以有效的方式交换效率的准确性，即在保持竞争性能的同时降低计算成本。**为了寻求一个良好的平衡，以前的努力通常集中于优化模型架构**。本文探讨了另一种方法，即重新分配一个尺度空间的计算。基本思想是稀疏地执行昂贵的检测，并通过大量廉价的网络，通过利用它们之间的强相关性，在大小和时间上传播结果。具体而言，**我们提出了一个统一的框架，将检测，时间传播和跨尺度精细化整合到一个Scale-Time格中**。在此框架中，可以探索各种策略来平衡性能和成本。利用这种灵活性，我们进一步开发一种自适应方案，并根据需要调用检测器，从而获得改进的折衷。在ImageNet VID数据集中，所提出的方法可以在20fps下达到79.6％的竞争性mAP，或者在62fps下达到79.0％作为性能/速度折衷。

##### Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding

可读性：★

关键词：行人再识别

摘要：在本文中，我们通过竞争性片段相似性聚合和共同细分的片段嵌入来**解决基于视频的行人再识别问题**。我们的方法将长时间序列分成多个短视频片段，并聚合序列相似性估计的排名最高的片段相似度。采用这种策略，每个样本的人内视觉变化可以被最小化以进行相似性估计，同时保持多样的外观和时间信息。片段相似性通过深度神经网络进行估计，其中片段嵌入具有新颖的时间共同注意力。注意权重是基于查询特征获得的，该特征是通过LSTM网络从整个探测片段中学习的，使得产生的嵌入较少受到噪声帧的影响。图库片段与探针片段共享相同的查询功能。因此，图库片段的嵌入可以呈现更多相关特征以与探针片段进行比较，从而产生更准确的片段相似性。广泛的消融研究验证了竞争性片段相似性聚合的有效性以及时间共注意嵌入。我们的方法在多个数据集上显着优于当前最先进的方法。

##### Fast and Accurate Online Video Object Segmentation via Tracking Parts

可读性：★★★

关键词：视频目标分割

摘要：在线视频目标分割是一项具有挑战性的任务，因为它需要及时和准确地处理图像序列。为了通过视频分割目标对象，已经开发了许多基于CNN的方法，通过在第一帧中严格调整对象掩模，这对于在线应用来说是耗时的。在本文中，我们提出了一种快速准确的视频对象分割算法，一旦接收图像就可以立即开始分割过程。我们首先利用基于部位的跟踪方法来处理具有挑战性的因素，例如大变形，遮挡和混乱的背景。基于跟踪的部位边界框，我们构建了一个感兴趣区域分割网络来生成部位掩模。最后，通过将这些目标部位与第一帧中的视觉信息进行比较，采用基于相似性的评分函数来细化这些目标部位。我们的方法在DAVIS基准数据集的准确性上优于最先进的算法，同时实现更快的运行时性能。

代码：[FAVOS](https://github.com/JingchunCheng/FAVOS)

##### Context-aware Deep Feature Compression for High-speed Visual Tracking

可读性：★★★★★

关键词：目标跟踪，高速

摘要：我们提出了一种新的基于上下文感知的相关滤波器跟踪框架，以实现实时跟踪器之间的高计算速度和最先进的性能。对高计算速度的主要贡献在于所提出的**深度特征压缩**，其通过利用多个专家自动编码器的情境感知方案来实现;我们框架中的上下文是指根据外观模式的跟踪目标的粗略类别。在预训练阶段，每个类别训练一个专家自动编码器。在跟踪阶段，为给定目标选择最佳专家自动编码器，并且仅使用该自动编码器。为了实现压缩特征映射的高跟踪性能，我们引入了外部去噪过程和新的正交性损失项，用于专家自动编码器的预训练和微调。我们通过大量实验来验证所提出的情景感知框架，在这些实验中，我们的方法达到了与不能实时运行的最先进跟踪器相当的性能，同时以超过100 fps的极快速度运行。

项目：[traca-project](https://sites.google.com/site/jwchoivision/home/traca)

##### Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification

可读性：★★★

关键词：行人再识别

摘要：在一个域上训练的行人再识别模型通常不能很好地概括到另一个域。在我们的尝试中，我们提出了一个“通过翻译学习”的框架。在基线中，我们以无监督的方式将标记图像从源域转换为目标域。然后，我们通过监督方法对翻译后的图像进行训练。然而，作为该框架的重要组成部分，无监督图像图像转换在翻译过程中遭受源域标签的信息丢失。我们的动机是双重的。首先，对于每张图片，其ID标签中包含的区分线索应在翻译后保留。其次，考虑到两个领域完全不同的人的事实，翻译后的图片应该与任何目标ID不相同。为此，我们建议保留两种类型的无监督相似性，1）翻译前后的图像的自相似性，以及2）翻译后的源图像和目标图像的域不相似性。这两个约束条件都是在由连体网络和CycleGAN组成的相似性保持生成对抗网络（SPGAN）中实现的。通过域适应实验，我们发现由SPGAN产生的图像更适合于域适应，并且在两个大规模数据集上产生一致且有竞争力的行人再识别准确性。

##### UV-GAN: Adversarial Facial UV Map Completion for Pose-invariant Face Recognition

可读性：★★

关键词：人脸识别，姿态不变性

摘要：最近提出的鲁棒3D人脸对齐方法建立了3D人脸模型和2D人脸图像之间的密集或稀疏对应关系。这些方法的使用带来了新的挑战以及面部纹理分析的机会。特别是，通过使用拟合模型对图像进行采样，可以创建面部UV。不幸的是，由于自闭症，这样的UV图总是不完整的。在本文中，我们提出了一个训练深度卷积神经网络（DCNN）的框架来完成从野外图像中提取的面部UV图。为此，我们首先通过将3D形变模型（3DMM）拟合到各种多视图图像和视频数据集以及利用具有超过3000个身份的新3D数据集来收集完整的UV地图。其次，我们设计了一个精心设计的架构，它结合了本地和全球敌对DCNN来学习保持身份的面部UV完成模型。我们证明，通过将完成的UV附加到拟合的网格并生成任意姿势的实例，我们可以增加姿势变化以训练深度人脸识别/验证模型，并在测试期间最小化姿势偏差，从而提高性能。在受控和野外UV数据集上的实验证明了我们的对抗UV完成模型的有效性。我们通过在训练期间结合姿势增强和在测试期间减少姿势差异来实现CFP前置曲线图协议下的现有验证准确度（94.05％）。我们将发布第一个野外UV数据集（我们称之为WildUV），其中包含1,892个身份的完整面部UV地图用于研究目的。

##### Deep Diffeomorphic Transformer Networks

可读性：★

关键词：数据增强

摘要：至少原则上，空间变换器层允许神经网络对于图像数据中的大空间变换是不变的。 然而，由于大多数实际实施仅支持太受限制的转换，所以该模型看起来受到限制，例如， 仿射图或同形映射图，和/或破坏性图，如薄板样条。 我们研究了在这样的网络中使用灵活的微分变换图像变换，并证明可以在当前使用的模型上获得显着的性能增益。 学到的转换被发现既简单又直观，从而提供对各个问题域的洞察。 利用所提出的框架，标准的卷积神经网络只需两条额外的简单TensorFlow代码就可以匹配面部验证的最新结果。

##### Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation

可读性：★

关键词：场景分割，语义分割

摘要：场景分割是一项具有挑战性的任务，因为它需要标记图像中的每个像素。利用区分性背景和聚合多尺度特征来实现更好的分割至关重要。在本文中，我们首先提出了一种新颖的上下文对比局部特​​征，它不仅利用了信息上下文，而且还聚焦了与上下文相反的局部信息。提出的上下文对比了局部特征，大大提高了解析性能，特别是对于不明显的对象和背景的东西。此外，我们提出门控求和方案来选择性地聚合每个空间位置的多尺度特征。该方案中的门​​控制不同尺度特征的信息流。它们的值由测试图像生成，由建议网络从训练数据中学习，这样它们不仅适应训练数据，而且适应特定的测试图像。没有花里胡哨的工作，所提出的方法在三种流行的场景分割数据集，Pascal上下文，SUN-RGBD和COCO Stuff上实现了一致的SOT水平。

##### Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning

可读性：★★★

关键词：目标跟踪，视觉跟踪

摘要：超参数是数值预设的，其取值是在学习过程开始之前分配的。**选择合适的超参数对于跟踪算法的准确性至关重要，但很难确定它们的最优值，特别是对于每个特定视频序列的自适应参数**。大多数超参数优化算法都依赖于搜索一个通用范围，并且它们被盲目地应用于所有序列。在这里，我们提出了一种新的超参数优化方法，它可以利用连续深度Q学习的动作预测网络为给定序列找到最优超参数。用于目标跟踪任务的公共状态空间比传统控制问题中的复杂得多，所以现有的连续深度Q学习算法不能直接应用。为了克服这个挑战，我们引入了一种有效的启发式方法来加速收敛行为。我们在几个跟踪基准上评估我们的方法，并展示其卓越的性能。

##### Wing Loss for Robust Facial Landmark Localisation with Convolutional Neural Networks

可读性：★★

关键词：人脸关键点检测

摘要：我们提出了一个新的损失函数，即**Wing Loss**，用于利用CNN进行鲁棒的人脸关键点检测。我们首先比较和分析不同的损失函数，包括L2，L1和平滑的L1。对这些损失函数的分析表明，**对基于CNN的模型训练，应该更加关注中小范围的损失**。为此，我们设计了一个分段式损失函数。新损失通过从L1损失切换到修改的对数函数来放大来自间隔（-w，w）的损失的影响。为了解决训练集中具有较大的平面外头部旋转的样本代表性不足的问题，我们提出了一种简单而有效的提升策略，称为基于姿势的数据平衡。特别是，我们通过复制少数训练样本并通过注入随机图像旋转，边界框平移和其他数据增强方法来干扰数据不平衡问题。最后，提出的方法被扩展为创建用于强健人脸关键点检测的两阶段框架。在AFLW和300W上获得的实验结果证明了Wing Loss函数的优点，并且证明了所提出的方法优于最先进的方法的优越性。

代码：[Wing-Loss](https://github.com/FengZhenhua/Wing-Loss)

##### Deep Ordinal Regression Network for Monocular Depth Estimation

可读性：★★★

关键词：单目深度估计

摘要：单目深度估计在理解3D场景几何中起着至关重要的作用，是一个棘手的问题。最近的方法通过探索来自深度卷积神经网络（DCNN）的图像级信息和分层特征而获得显著改善。这些方法将深度估计作为回归问题进行建模，并通过最小化均方误差来训练回归网络，其中收敛缓慢且局部解决方案不令人满意。此外，现有的深度估计网络采用重复的空间池操作，导致不满足需要的低分辨率特征图。为了获得高分辨率深度图，需要跳过连接或多层反卷积网络，这使得网络训练变得复杂并且消耗更多的计算量。为消除或至少在很大程度上减少这些问题，我们引入了一种间距增加离散化（SID）策略来将深度和重铸深度网络学习作为序数回归问题进行离散化。通过使用普通回归损失对网络进行训练，我们的方法实现了更高的准确性和更快的同步收敛。此外，我们采用了多尺度网络结构，避免了不必要的空间合并，并行捕获多尺度信息。所提出的深度顺序回归网络（DORN）在KITTI [16]，Make3D [49]和NYU Depth v2 [41]三个具有挑战性的基准测试中达到了最新的结果，并且其性能优于现有方法余量。

代码：[DORN](https://github.com/hufu6371/DORN)

##### Dynamic Zoom-in Network for Fast Object Detection in Large Images

可读性：★★★★

关键词：目标检测，高分辨率图像

摘要：我们引入了一个通用框架，该框架可降低目标检测的计算成本，同时保持对高分辨率图像中出现大小不同的目标的场景精度。检测以粗到细的方式进行，首先在图像的下采样上，然后在被识别为可能提高检测精度的更高分辨率区域的序列上进行。基于强化学习，我们的方法由一个模型（Rnet）组成，该模型使用粗略检测结果来预测分析较高分辨率区域的潜在准确度增益，以及依次选择要放大的区域的另一个模型（Q-net）。实验在加州理工学院的行人数据集上显示，我们的方法将处理后的像素数量减少了50％以上，检测精度没有下降。我们的方法的优点在从YFCC100M数据集收集的高分辨率测试集中变得更加重要，其中我们的方法保持高检测性能，同时将处理像素数量减少约70％并且检测时间减少超过50％。

##### Detect-and-Track: Efficient Pose Estimation in Videos

可读性：★★★★

关键词：目标跟踪，视觉跟踪

摘要：本文讨论了**在复杂的多人视频中估计和跟踪人体关键点的问题**。我们提出了一种非常轻便但非常有效的方法，它建立在人体检测[17]和视频理解[5]方面的最新进展之上。我们的方法分为两个阶段：帧或短片段中的关键点估计，然后是轻量级跟踪，以生成关联整个视频的关键点预测。对于帧级姿态估计，我们尝试使用Mask R-CNN以及我们自己提出的此模型的3D扩展，该扩展利用小片段上的时间信息来生成更强健的帧预测。我们在新发布的多人视频姿态估计基准PoseTrack上进行了广泛的消融实验，以验证我们模型的各种设计选择。我们的方法使用多目标跟踪精度（MOTA）度量方法实现验证的准确率为55.2％，测试集的准确度为51.8％，并且实现了ICCV 2017 PoseTrack关键点跟踪挑战的最新性能表现。

代码：[DetectandTrack](https://github.com/facebookresearch/DetectAndTrack)

##### DensePose: Dense Human Pose Estimation In The Wild

可读性：★

关键词：行人姿态估计

摘要：在这项工作中，我们建立了RGB图像和基于表面的人体表示之间的密集对应关系，我们称之为**密集人体姿态估计**。通过引入高效的注释管道，我们为出现在COCO数据集中的5万人收集密集对应关系。然后，我们使用我们的数据集来训练基于CNN的系统，这些系统能够在野外提供密集的对应关系，即存在背景，遮挡和尺度变化。我们通过训练一个修复网络来提高我们的训练数据集的有效性，修复网络可以填写缺少的基础真值并报告有关过去可实现的最佳结果的改进。我们试验全卷积网络和区域模型，并观察后者的优越性。我们通过级联进一步提高了准确性，获得了一个系统，可以在单个GPU上以每秒多帧的速度提供高精度的结果。

项目：[DensePose](http://densepose.org/)

##### Efficient and Deep Person Re-Identification using Multi-Level Similarity

可读性：★★★★★

关键词：行人再识别

摘要：行人再识别（ReID）要求比较在不同条件下拍摄的行人的两幅图像。基于神经网络的现有工作通常计算单个卷积层的特征映射的相似性。在这项工作中，我们提出了一个高效的端到端全卷积栾生网络，计算多个层次的相似度。我们证明多级相似性可以在ReID问题中使用低复杂性网络结构大大提高准确性。具体来说，首先，我们使用几个卷积层来提取两个输入图像的特征。然后，我们提出卷积相似性网络来计算输入的相似度分数图。我们使用空间变换网络（STN）来确定空间关注。我们建议应用高效深度卷积来计算相似度。所提出的卷积相似性网络可以被插入不同的卷积层以提取不同级别的视觉相似性。此外，我们使用改进的排名损失来进一步提高性能。我们的工作是首次提出计算ReID的低，中，高级视觉相似度。通过广泛的实验和分析，我们证明我们的系统紧凑而有效，可以通过更小的模型尺寸和计算复杂性来实现竞争结果。

##### A Twofold Siamese Network for Real-Time Object Tracking

可读性：★★★★★

关键词：实时目标跟踪

摘要：由于观察到在图像分类任务中学习到的语义特征和在相似匹配任务中学习到的外观特征相互补充，我们构建了一个名为SA-Siam的双重连接网络，用于实时目标跟踪。SA-Siam由语义分支和外观分支组成。每个分支都是一个相似学习的栾生网络。SA-Siam的一个重要设计是分别训练两个分支以保持两种特征的异质性。另外，我们提出了语义分支的渠道关注机制。通道权重根据目标位置周围的通道激活进行计算。虽然SiamFC的继承体系结构允许我们的跟踪器实时运行，但双重设计和关注机制显着提高了跟踪性能。在OTB-2013/50/100基准测试中，拟议的SA-Siam优于所有其他实时跟踪器。

##### Deep Spatial Feature Reconstruction for Partial Person Re-identification: Alignment-free Approach

可读性：★★★

关键词：行人再识别

摘要：行人再识别是一个具有挑战性的问题，只有几个人的部分观察（图像）可用于匹配。然而，**很少有研究提供灵活的解决方案来识别包含身体任意部分的图像中的人**。在本文中，我们提出了一种快速而准确的匹配方法来解决这个问题。所提出的方法利用全卷积（FCN）生成固定尺寸的空间特征图，使得像素级特征一致。为了匹配一对不同尺寸的人物图像，进一步开发了称为深空间特征重建（DSR）的新方法以避免明确对齐。具体来说，DSR利用流行字典学习模型中的重构误差来计算不同空间特征地图之间的相似度。通过这种方式，我们预计所提出的FCN可以减少来自不同人的耦合图像的相似性并且增加来自同一个人的图像的相似性。关于两个遮挡行人数据集的实验结果证明了与几种现有技术的行人再识别方法相比，所提出的方法的效率和有效性。此外，DSR在基准人数数据集Market1501上获得了具有83.58％Rank-1准确度的竞争结果。

代码：[Code](https://github.com/lingxiao-he/Deep-Spatial-Feature-Reconstruction-for-Partial-Person-Re-identification)

##### Dynamic Feature Learning for Partial Face Recognition

可读性：★★★

关键词：人脸识别

摘要：**部分人脸识别（PFR）在无约束的环境中是一项非常重要的任务**，尤其是在视频监控，移动设备等方面。然而，一些研究已经解决了如何识别人脸图像的任意块。本研究将全卷积（FCN）与稀疏表示分类（SRC）相结合，提出了一种称为动态特征匹配（DFM）的新型局部人脸识别方法，以解决部分人脸图像无论大小如何。基于DFM，我们提出了一种滑动损失优化FCN的方法，通过减少面片和人脸图像之间的内部变化，进一步提高了DFM的性能。所提出的DFM在几个遮挡人脸数据库上进行评估，包括LFW，YTF和CASIA-NIR-Distance数据库。实验结果证明了DFM与最先进的PFR方法相比的有效性和优势。

##### Improving Landmark Localization with Semi-Supervised Learning

可读性：★

关键词：人脸关键点检测

摘要：我们提出了两种技术来提高部分注释数据集图像中的关键点定位。我们的主要目标是利用普通情况，即精确的关键点定位仅为小数据子集提供，但与关键点相关的分类或回归任务的类别标签更丰富。首先，我们提出顺序多任务处理框架，并通过关键点定位架构在这里探索它，其中类别标签的训练作为辅助信号来指导未标记数据的关键点定位。我们方法的一个关键方面是可以通过完整的关键点定位模型反向传播误差。其次，我们提出并探索了一种基于模型预测等效关键点与应用于图像变换的关键点定位的无监督学习技术。我们表明，这些技术，大大改善关键点定位效果，并可以学习有效的检测器，即使只有一小部分数据集具有关键点的标签。我们将结果显示在两个模拟数据集和四个真实数据集上，包括手和脸部，并在野外的两个数据集上报告最新的最新技术。只有5％的标记图像胜过了先前在AFLW数据集上进行的最先进的训练。

##### Learning to Segment Every Thing

可读性：★

关键词：实例分割

摘要：大多数用于对象实例分割的方法都要求用分割掩模来标记所有训练示例。这个要求使得注释新的类别变得很昂贵，并且将实例分割模型限制在大约100个注释良好的类中。本文的目标是提出一种新的部分监督训练范式，以及一种新颖的权重传递函数，它能够对大量类别中的训练实例分割模型进行训练，所有这些类别都有框注释，但只有一小部分具有框注释掩码注释。通过这些贡献，我们可以训练Mask R-CNN使用Visual Genome数据集中的框注释和COCO数据集中80个类的掩码注释来检测和分割3000个视觉概念。我们在COCO数据集的对照研究中评估我们的方法。这项工作是对具有广泛理解视觉世界的实例细分模型的第一步。

##### Relation Networks for Object Detection

可读性：★★★★

关键词：目标检测关联网络

摘要：尽管多年来人们相信，目标之间的建模关系有助于对象识别，但还没有证据表明这个想法在深度学习时代有效。所有最先进的目标检测算法仍然依赖于单独识别目标实例，而不需要在学习期间利用它们之间的关系。这项工作提出了一个目标关系模块。它通过外观特征和几何图形之间的相互作用同时处理一组目标，从而允许建立它们之间的关系。它权重数量少并且是内嵌的。它不需要额外的监督，并且很容易嵌入现有网络。在现代物体检测流水线中，它对改善物体识别和清除重复步骤有效。它验证了建模目标关系在基于CNN的检测中的功效。它产生了第一个完全端对端的目标检测器。

##### Squeeze-and-Excitation Networks（SENet）

可读性：★★

关键词：网络结构

摘要：卷积神经网络建立在卷积运算的基础上，通过融合本地感受域内的空间信息和信道信息来提取信息特征。为了提高网络的表现能力，最近的几种方法已经显示出增强空间编码的好处。在这项工作中，我们关注通道关系并提出了一种新颖的架构单元，我们称之为“挤压和激励”（SE）模块，通过显式建模通道之间的相关性来自适应重新校准通道特征响应。我们证明，通过将这些块堆叠在一起，我们可以构建SENet体系结构，在具有挑战性的数据集中进行非常好的泛化。至关重要的是，我们发现SE块以最小的额外计算成本为现有技术的深层架构产生显着的性能改进。SENets组成了我们ILSVRC 2017分类提交的基础，赢得了第一名，并将top-5的误差显著降低至2.251％，与2016年的获胜者相比，获得了约25％的相对改进。

代码：[SENet](https：// github.com/hujie-frank/SENet)

##### Pointwise Convolutional Neural Networks

可读性：★★★★

关键词：点云卷积，语义分割，目标识别

摘要：3D数据的深度学习，如重建点云和CAD模型，近来获得了极大的研究兴趣。然而，卷积神经网络使用点云的能力还没有完全探索。在本文中，我们提出了一个用于三维点云的语义分割和对象识别的卷积神经网络。我们网络的核心是逐点卷积，一种新的卷积算子，可应用于点云的每个点。我们的全卷积网络设计虽然实现起来非常简单，但却可以在**语义分割和对象识别任务**中产生有竞争力的准确性。

代码：[PCNN](https://github.com/scenenn/pointwise)

##### Adversarially Occluded Samples for Person Re-identification

可读性：★

关键词：行人再识别

摘要：行人再识别（ReID）是通过不同摄像头检索特定人员的任务。尽管近年来取得了长足的进步，但它仍然面临着**姿势变化，遮挡以及不同人物之间相似外观等挑战**。训练和测试性能与现有模型之间的巨大差距意味着泛化的不足。考虑到这个事实，我们建议通过引入对抗遮挡样本来增加训练数据的变化。这些特殊样本是a）有意义的，因为它们类似于真实场景遮挡，并且b）有效，因为它们对于原始模型是艰难的，因此提供跳出局部最优的动力。我们根据训练有素的ReID模型和网络可视化技术的帮助来挖掘这些样本。大量的实验表明，所提出的样本可以帮助模型发现身体上新的区分线索，并在测试时更好地推广。我们的战略在三个大型ReID数据集Market1501，CUHK03和DukeMMC-reID的强基线方面做出了重大改进。

##### CondenseNet: An Efficient DenseNet using Learned Group Convolutions

可读性：★★★★

关键词：网络结构，紧凑型网络

摘要：深度神经网络越来越多地用于计算资源有限的移动设备。在本文中，我们开发了具有前所未有的效率的新型网络架构CondenseNet。它将密集连接与称为学习群组卷积的新模块相结合。密集的连通性有利于网络中的特征重用，而学习的群组卷积消除了该特征重复使用的层之间的连接是多余的。在测试时，我们的模型可以使用标准组卷积来实现，从而在实践中实现高效的计算。我们的实验表明CondenseNets比ShuffleNets等最先进的紧凑卷积网络更有效率。

代码：[CondenseNet](https://github.com/ShichenLiu/CondenseNet)

##### LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation

可读性：★★★★★

关键词：光流估计

摘要：用于光流估计的最先进的卷积神经网络（CNN）FlowNet2需要超过**160M的参数**才能实现精确的流量估计。在本文中，我们提出了一个替代网络，该网络在具有挑战性的Sintel最终通过和KITTI基准测试中获得与FlowNet2相同的性能，同时**模型尺寸缩小30倍，运行速度提高1.36倍**。这可以通过深入到当前框架中可能错过的架构细节来实现：（1）我们通过轻量级联网络在每个金字塔等级提供更有效的流量推断方法。它不仅通过早期修正提高了流量估计的准确性，而且还允许在我们的网络中无缝并入描述符匹配。（2）通过使用特征驱动的局部卷积，我们提出了一种新颖的流动正则化层来改善异常值和模糊流动边界的问题。（3）我们的网络拥有用于金字塔特征提取的有效结构，并且包含了FlowNet2中实现的特征翘曲而非图像翘曲。

代码：[LiteFlowNet](https://github.com/twhui/LiteFlowNet)

##### Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference

可读性：★★

关键词：模型优化压缩，量化

摘要：智能移动设备的日益普及以及基于深度学习的模型的巨大计算成本要求高效且准确的设备推断方案。 我们提出了一种量化方案，它允许使用整数运算来进行推理，该算法可以比通常可用的纯整数硬件上的浮点推断更有效地实现。我们还共同设计了一个训练过程来保留量化后的端对端模型精度。 结果，所提出的量化方案改善了准确度和器件上等待时间之间的折衷。即使在运行时效率较高的模型系列MobileNets上，这些改进也很有意义，并且在流行CPU上的ImageNet分类和COCO检测中得到了演示。

##### Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference

可读性：★★

关键词：模型优化压缩，量化

摘要：智能移动设备的日益普及以及基于深度学习的模型的巨大计算成本要求高效且准确的设备推断方案。 我们提出了一种量化方案，它允许使用整数运算来进行推理，该算法可以比通常可用的纯整数硬件上的浮点推断更有效地实现。我们还共同设计了一个训练过程来保留量化后的端对端模型精度。 结果，所提出的量化方案改善了准确度和器件上等待时间之间的折衷。即使在运行时效率较高的模型系列MobileNets上，这些改进也很有意义，并且在流行CPU上的ImageNet分类和COCO检测中得到了演示。

代码：[LiteFlowNet](https://github.com/twhui/LiteFlowNet)





