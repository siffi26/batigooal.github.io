---
title: CVPR2018论文整理
date: 2018-06-13 13:45:23
categories: 资料汇总
tags:
     - resources
---
##### Learning Pixel-level Semantic Affinity with Image-level Supervision for Weakly Supervised Semantic Segmentation

关键词：弱监督训练，语义分割

摘要：为了解决分割标签制作的低效率问题，文章提出了一个新的框架，**根据图像级别的类别标签生成图像的语义标签**。在这种弱监督环境中，我们知道训练过的模型可以分割局部区域而不是整个物体区域。我们的方法是将这种本地响应传播到属于同一语义整体的相邻区域。为此，我们提出一个叫做AffinityNet的深度神经网络用于预测一对相邻图像坐标之间的语义亲和度。然后，通过AffinityNet预测亲和性随机游走来实现语义传播。更重要的是，用来训练AffinityNet的监督信号是由初始判别性部分分割给出的，它作为分割标注来说是不完全的，但是足够学习小图像区域内的语义亲和度。因此，整个框架仅仅依赖于图像级的类别标注，并不需要额外数据或标注。在VOC2012数据集上，使用我们方法生成的分割标注学习的DNN效果优于之前用相同监督水平训练的模型，甚至与那些依赖强监督的模型相比也是具有竞争力的。

##### A PID Controller Approach for Stochastic Optimization of Deep Networks

可读性：★★★

关键词：训练优化方法，PID控制

摘要：深度神经网络已经在许多计算机视觉应用中证明了它们的能力，如VGG，ResNet和DenseNet之类的最先进的模型主要通过SGD-Momentum算法进行优化，该算法通过考虑过去和当前的梯度来更新权重。尽管如此，**SGD-Momentum仍存在超调问题**，阻碍了网络训练的融合。受自动控制中PID控制器成功的启发，我们提出了一种用于加速深度网络优化的PID方法。我们首先揭示了SGD-Momentum和基于PID的控制器之间的内在联系，然后介绍利用过去，当前和梯度变化来更新网络参数的优化算法。**所提出的PID方法大大减少了SGD-Momentum的过冲现象**，并且通过我们对基准数据集（包括CIFAR10，CIFAR100和Tiny-ImageNet）的实验验证，它可以在具有竞争精度的DNN架构上实现高达50％的加速。

代码：[PIDOptimizer](https://github.com/tensorboy/PIDOptimizer)

备注：PID控制的思想引入到模型训练的随机优化过程，据说效果不错，但是主要优点在与可以加速训练收敛的速度，有空可以自己跑一下代码试试。

##### Finding Tiny Faces in the Wild with Generative Adversarial Network

关键词：人脸检测，生成对抗网络

摘要：人脸检测技术已经发展了数十年，其中一个尚未解决的挑战是**在无约束的条件下检测小脸**。原因是**微小的脸部往往缺乏详细的信息和模糊**。在本文中，我们提出了一种算法，通过采用生成对抗网络（GAN），从模糊的小模型直接生成清晰的高分辨率人脸。基本的GAN通过超分辨率和精细化（例如SR-GAN和cycle-GAN）来实现。但是，我们设计了一个新颖的网络来解决超解决和共同提炼的问题。我们还引入了新的训练损失，以指导发生器网络恢复细节，并促使鉴别器网络同时区分真假和脸部/非脸部。在具有挑战性的数据集WIDER FACE上进行的大量实验证明我们提出的方法能够从一个模糊的小图像恢复清晰的高分辨率人脸，并显示其检测性能优于其他最先进的方法。

##### The power of ensembles for active learning in image classification

可读性：★★

关键词：主动学习

摘要：深度学习方法已成为挑战图像处理任务（如图像分类）的事实标准。深度学习方法的一个主要障碍是需要大量的标记数据，这可能会导致昂贵的成本，特别是在医学图像诊断应用中。**主动学习技术**可以缓解这种标签工作。在本文中，我们研究一些最近提出的用于高维数据和卷积神经网络分类器的主动学习方法。我们比较了基于集合的方法与蒙特卡洛压差和几何方法。我们发现集成表现更好，并导致更多校准的预测不确定性，这是许多主动学习算法的基础。为了调查为什么蒙特卡罗辍学不确定性表现更差，我们在一系列实验中探索了孤立性的潜在差异。我们展示了MNIST和CIFAR-10的结果，其中我们用大约12,200个标记图像获得了90％的测试集精度，并在ImageNet上获得了初始结果。此外，我们在大型高度不平衡的糖尿病性视网膜病变数据集上展示结果。我们观察到，基于集成的主动学习方法有效地抵消了不平衡的影响。

备注：介绍了主动学习和集成学习相结合的方法。

##### Dense Decoder Shortcut Connections for Single-Pass Semantic Segmentation

可读性：★★

关键词：语义分割，Dense Decoder

摘要：我们提出了一种**用于单通道语义分割的新型端到端可训练深度编码器解码器架构**。我们的方法基于具有功能级远程跳过连接的级联架构。该编码器结合了ResNeXt残差构建模块的结构，并采用重复构建模块的策略，该构建模块汇总了具有相同拓扑的一组变换。该解码器具有一种新颖的架构，由块组成，这些架构包括（i）捕获上下文信息，（ii）生成语义特征，以及（iii）实现不同输出分辨率之间的融合。至关重要的是，我们引入了密集的解码器快捷连接，以允许解码器块使用来自所有先前解码器级别的语义特征映射，即来自所有更高级别的特征映射。密集的解码器连接允许从一个解码器块到另一个解码器块的有效信息传播，以及多级特征融合，从而显着提高准确性。重要的是，这些连接使我们的方法能够在几个具有挑战性的数据集上获得最先进的性能，而不需要之前多尺度工作那样的平均耗时。

##### Cascade R-CNN: Delving into High Quality Object Detection

可读性：★★★★★

关键词：级联R-CNN，目标检测

摘要：在目标检测中，需要通过IoU阈值来定义正例和负例。用低IoU阈值进行训练的目标检测器，如0.5，通常会产生嘈杂的检测结果。但是，**IoU阈值增加后检测性能会降低**。造成这种情况的原因有两个：1）正样本太少会导致训练过拟合；2）推理时间不匹配。本文提出了级联检测算法Cascade R-CNN用于解决这些问题。它由一系列IoU阈值增加而训练的检测器组成，以对接近的假阳性依次更具有选择性。目标检测器逐步进行训练，利用观测器的输出是一个良好的分布来训练下一个更高质量的目标检测器。逐步改进假设的重采样从而保证所有目标检测器都有一组正确的等效大小样本，减少过拟合的情况。在部署中应用相同的级联结构，使得假设和每个阶段的目标检测器质量之间更接近匹配。级联R-CNN的简单实现超过COCO数据集上所有单模型目标检测器。实验还表明，级联R-CNN可广泛应用于不同的目标检测器架构，获得与基准检测器强度无关的一致增益。

代码：[Cascade R-CNN](https://github.com/zhaoweicai/cascade-rcnn)

备注：R-CNN的级联结构，应该是高分辨率图像中目标检测算法的趋势。

##### Deep Cauchy Hashing for Hamming Space Retrieval

关键词：图像检索，哈希编码

摘要：哈希算法由于其计算效率和检索质量，已被广泛应用于近似最近邻搜索的大规模图像检索，而深度哈希通过端到端表示学习和哈希编码进一步提高了检索质量。通过紧凑的散列码，海明空间检索可实现最有效的恒定时间搜索，该搜索可通过散列表查找而不是线性扫描将给定汉明半径内的数据点返回给每个查询。然而，由于错误指定的损失函数，将相关图像集中在小海明球内的能力较弱，现有的深度哈希方法可能会因海明空间检索而表现不佳。这项工作提出了Deep Cauchy Hashing（DCH），这是一种新颖的深度哈希模型，可生成紧凑且集中的二进制哈希代码，从而实现高效的海明空间检索。其主要思想是设计一个基于柯西分布的成对交叉熵损失，在海明距离大于给定的汉明半径阈值的情况下，对相似图像对产生显著的惩罚。综合实验表明，DCH可以生成高度集中的散列码，并在三个数据集NUS-WIDE，CIFAR-10和MS-COCO上产生最先进的海明空间检索性能。

##### HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN

关键词：图像检索，哈希编码

摘要：深度哈希通过端对端表示学习和来自具有成对相似性信息的训练数据的哈希编码来改善图像检索性能。由于相似性信息的稀缺性对于许多应用领域来说通常很昂贵，所以现有的对哈希方法的深度学习可能过度训练数据并导致检索质量的显著损失。本文介绍了HashGAN，一种用于深入学习哈希的新颖体系结构，它从真实图像和由生成模型合成的各种图像学习紧凑二进制哈希码。其主要思想是增加训练数据，用几乎真实的图像合成一个新的Pair Conditional Wasserstein GAN（PC-WGAN）条件成对相似性信息。大量实验表明，HashGAN可以生成高质量的二进制散列码，并在NUS-WIDE，CIFAR-10和MS-COCO三个基准测试中获得最先进的图像检索性能。

##### Partially Shared Multi-Task Convolutional Neural Network with Local Constraint for Face Attribute Learning

可读性：★★★

关键词：人脸属性识别

摘要：在本文中，我们同时考虑身份信息和属性关系来研究人脸属性的学习问题。具体而言，我们首先引入部分共享多任务卷积神经网络（PS-MCNN），其中四个任务专用网络（TSNets）和一个共享网络（SNet）通过部分共享（PS）结构连接以学习更好的共享和任务特定的表示。为了利用身份信息来进一步提高性能，我们引入了局部学习约束，该约束将每个样本与其具有相同身份的局部几何领域的表示之间的差异最小化。因此，我们提出了一个局部约束正规化的多任务网络，称为局部共享多任务卷积神经网络与局部约束（PS-MCNNLC），其中PS结构和局部约束集成在一起，以帮助框架学习更好的属性表示。CelebA和LFWA的实验结果证明了所提出方法的前景

##### Pose-Robust Face Recognition via Deep Residual Equivariant Mapping

可读性：★★★★★

关键词：人脸识别

摘要：由于深度学习的出现，人脸识别取得了非凡的成功。然而，与正面相比，许多当代人脸识别模型在处理人脸时仍然表现较差。**一个关键的原因是正面和侧面训练面孔的数量高度不平衡**。与侧面训练样本相比，正面训练样本更多。此外，从本质上来说，**很难学习一个对于大姿态变化下具有几何不变性的深度表示**。在本研究中，我们假设前面和侧面之间存在固有的映射关系，因此它们在深度表示空间中的差异可以通过等变映射来弥补。为了利用这种映射，我们制定了一种新颖的深度残差等熵映射（DREAM）块，它能够自适应地将残差添加到输入深度表示中，**以将剖面人脸表示转换为简化识别的典型姿态**。DREAM模块不断加强许多强大深度网络（包括ResNet模型）的轮廓人脸识别性能，而不会有意增加轮廓面的训练数据。该模块易于使用，重量轻，并且可以用可忽略的计算开销1来实现。

代码：[DREAM](https://github.com/penincillin/DREAM)

备注：[中文解读](http://www.sohu.com/a/225437836_129720)

##### “Learning-Compression” Algorithms for Neural Net Pruning

可读性：★★★

关键词：剪枝，模型压缩，模型优化

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

##### Deep Spatio-Temporal Random Fields for Efficient Video Segmentation

可读性：★★

关键词：视频分割

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

代码：[gcrf](https://github.com/siddharthachandra/gcrf)

##### Multi-Level Factorisation Net for Person Re-Identification

可读性：★★★★

关键词：行人再识别

摘要：有效的行人再识别（Re-ID）的关键是**在高和低的语义层次上对行人外观的区别性和视角不变因素进行建模**。最近开发的深度Re-ID模型**要么学习整体单一语义级别的特征表示和/或需要这些因素的费力的人类注释作为属性**。我们提出了**多层次因子网（MLFN）**，这是一种新颖的网络架构，可将人的视觉外观在多种语义层次上分解为潜在的判别因子，无需人工注释。MLFN由多个堆叠块组成。每个块包含多个因子模块以模拟特定级别的潜在因子，因子选择模块动态选择因子模块以解释每个输入图像的内容。因子选择模块的输出还提供了一个紧凑的潜在因子描述符，它与传统的深度学习特征相辅相成。MLFN在三个Re-ID数据集上实现了最先进的结果，并在通用对象分类CIFAR-100数据集上获得了令人瞩目的结果。

##### Pyramid Stereo Matching Network

可读性：★★★

关键词：双目深度估计

摘要：最近的研究表明，从一对立体图像进行深度估计可以被制定为一个监督学习任务，用卷积神经网络（CNN）来解决。然而，目前的体系结构依赖于基于补丁的连体网络，缺乏利用上下文信息来找到在所示区域的对应关系的手段。为了解决这个问题，我们提出PSMNet，一个由两个主要模块组成的金字塔立体匹配网络：空间金字塔池和3D-CNN。空间金字塔池模块通过聚合不同尺度和位置的上下文来利用全局上下文信息的能力来调整惩罚量。3D-CNN学习使用堆叠的多个沙漏网络结合中间监督来调整惩罚量。所提出的方法在几个基准数据集上进行了评估。 我们的方法在2018年3月18日之前的KITTI 2012和2015排行榜中排名第一。

代码：[PSMNet](https://github.com/JiaRenChang/PSMNet)

##### Cascaded Pyramid Network for Multi-Person Pose Estimation

可读性：★

关键词：多人姿态估计，关键点检测

摘要：多人姿态估计近年来得到了很大的改善，特别是随着卷积神经网络的发展。然而，仍然存在很多具有挑战性的案例，例如**闭塞的关键点，不可见的关键点和复杂的背景**，这些都不能很好地解决。在本文中，我们提出了一种称为级联金字塔网络（CPN）的新型网络结构，其目标是从这些“硬”关键点解决问题。更具体地说，我们的算法包括两个阶段：GlobalNet和RefineNet。GlobalNet是一个功能金字塔网络，可以成功定位像眼睛和手这样的“简单”关键点，但可能无法准确识别被遮挡或不可见的关键点。我们的RefineNet试图通过集成GlobalNet的所有级别的特征表示以及在线硬关键点挖掘损失来明确处理“硬”关键点。通常，为了解决多人姿态估计问题，采用自顶向下的管线首先根据检测器生成一组人类边界框，然后在每个人体边界框中用CPN进行关键点定位。基于所提出的算法，我们在COCO关键点基准测试中获得了最先进的结果，COCO测试开发数据集的平均精度为73.0，COCO测试挑战数据集的平均精度为72.1，与60.5相比，相对提高了19％来自COCO 2016关键挑战。 Code1以及所使用人员的检测结果将公开发布供进一步研究。

代码：[CPN](https://github.com/chenyilun95/tf-cpn)

##### Deep Hashing via Discrepancy Minimization

关键词：哈希编码，图像检索

摘要：本文提出了一个差异最小化模型来解决**哈希学习中的离散优化问题**。二元约束引入的离散优化是一个NP难混合整数规划问题。通常通过将二进制变量放宽为连续变量来适应基于梯度的哈希函数学习，特别是深度神经网络的训练。针对松弛引起的客观差异，将原始二元优化问题转化为哈希函数可微分优化问题。该变换将二进制约束和相似性保持散列函数优化解耦。转换后的目标在一个易处理的交替优化框架中进行了优化，并逐步减少了差异。在三个基准数据集上的广泛实验结果验证了所提出的差异使散列最小化的有效性。

##### Group Consistent Similarity Learning via Deep CRF for Person Re-Identification

可读性：★★★

关键词：行人再识别

摘要：行人再识别从深度神经网络（DNN）中获益很多，以学习精确的相似性度量和强健的特征嵌入。然而，目前大多数方法仅对相似性学习施加局部约束。在本文中，我们将CRF与深度神经网络相结合，将大型图像组的约束纳入其中。所提出的方法旨在学习成对图像的“局部相似性”度量，同时考虑组中所有图像的相关性，形成“组相似性”。我们的方法涉及多个图像来模拟训练期间统一CRF中局部和全局相似性之间的关系，同时结合多尺度局部相似性作为测试中的预测相似性。我们采用近似推理方案来估计组相似性，从而实现端到端的培训。大量的实验证明了我们的模型的有效性，它结合了DNN和CRF来学习稳健的多尺度局部相似性。整体结果优于那些在三个广泛使用的基准上具有相当利润率的艺术家。

##### MaskLab: Instance Segmentation by Refining Object Detection with Semantic and Direction Features

可读性：★

关键词：实例分割

摘要：在这项工作中，我们解决了实例分割的问题，同时解决了对象检测和语义分割的任务。为了实现这个目标，我们提出了一个名为MaskLab的模型，它产生三个输出：box检测，语义分割和方向预测。建立在Faster-RCNN对象检测器之上，预测框提供了对象实例的精确定位。在每个感兴趣的区域内，MaskLab通过结合语义和方向预测来执行前景/背景分割。语义分割帮助模型区分包括背景在内的不同语义类别的对象，而方向预测（估计每个像素朝向其相应中心的方向）允许分离相同语义类别的实例。此外，我们还探讨了从分段和检测（例如，卷积和超列）中整合最新成功方法的效果。我们提出的模型在COCO实例细分基准上进行评估，并与其他最先进的模型进行比较。

##### Progressively Complementarity-aware Fusion Network for RGB-D Salient Object Detection 

可读性：★★★★

关键词：RGB-D，深度摄像头，目标检测

摘要：**如何充分结合跨模式互补是RGB-D显著物体检测的基石问题**。以前的作品主要通过简单地连接多模态特征或结合单峰预测来解决这个问题。在本文中，我们从两个角度回答了这个问题：（1）我们认为，如果互补部分可以更明确地建模，那么跨模态补充可能会被更好地捕获。为此，我们在采用卷积神经网络（CNN）时设计了一种新型互补感知融合（CA-Fuse）模块。通过在每个CA-Fuse模块中引入交叉模态残差函数和互补意识监督，从成对模态中学习补充信息的问题被明确提出为渐近逼近残差函数。（2）探索各个层面的补充。通过级联CA-Fuse模块并添加从深层到深层的层级式监管，可以选择并逐步组合跨层次补充。所提出的RGB-D融合网络消除了跨模态和跨层次融合过程的歧义，并能够获得更充分的融合结果。公共数据集上的实验显示了所提出的CA-Fuse模块和RGB-D显着物体检测网络的有效性。

##### Optimizing Video Object Detection via a Scale-Time Lattice

可读性：★★★

关键词：视频目标检测

摘要：高性能对象检测依赖于昂贵的卷积网络来计算特征，这经常导致应用中的重大挑战，例如，那些需要实时从视频流中检测对象的应用程序。这个问题的关键是以有效的方式交换效率的准确性，即在保持竞争性能的同时降低计算成本。**为了寻求一个良好的平衡，以前的努力通常集中于优化模型架构**。本文探讨了另一种方法，即重新分配一个尺度空间的计算。基本思想是稀疏地执行昂贵的检测，并通过大量廉价的网络，通过利用它们之间的强相关性，在大小和时间上传播结果。具体而言，**我们提出了一个统一的框架，将检测，时间传播和跨尺度精细化整合到一个Scale-Time格中**。在此框架中，可以探索各种策略来平衡性能和成本。利用这种灵活性，我们进一步开发一种自适应方案，并根据需要调用检测器，从而获得改进的折衷。在ImageNet VID数据集中，所提出的方法可以在20fps下达到79.6％的竞争性mAP，或者在62fps下达到79.0％作为性能/速度折衷。

##### Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding

可读性：★

关键词：行人再识别

摘要：在本文中，我们通过竞争性片段相似性聚合和共同细分的片段嵌入来**解决基于视频的行人再识别问题**。我们的方法将长时间序列分成多个短视频片段，并聚合序列相似性估计的排名最高的片段相似度。采用这种策略，每个样本的人内视觉变化可以被最小化以进行相似性估计，同时保持多样的外观和时间信息。片段相似性通过深度神经网络进行估计，其中片段嵌入具有新颖的时间共同注意力。注意权重是基于查询特征获得的，该特征是通过LSTM网络从整个探测片段中学习的，使得产生的嵌入较少受到噪声帧的影响。图库片段与探针片段共享相同的查询功能。因此，图库片段的嵌入可以呈现更多相关特征以与探针片段进行比较，从而产生更准确的片段相似性。广泛的消融研究验证了竞争性片段相似性聚合的有效性以及时间共注意嵌入。我们的方法在多个数据集上显着优于当前最先进的方法。

##### Fast and Accurate Online Video Object Segmentation via Tracking Parts

可读性：★★★

关键词：视频目标分割

摘要：在线视频目标分割是一项具有挑战性的任务，因为它需要及时和准确地处理图像序列。为了通过视频分割目标对象，已经开发了许多基于CNN的方法，通过在第一帧中严格调整对象掩模，这对于在线应用来说是耗时的。在本文中，我们提出了一种快速准确的视频对象分割算法，一旦接收图像就可以立即开始分割过程。我们首先利用基于部位的跟踪方法来处理具有挑战性的因素，例如大变形，遮挡和混乱的背景。基于跟踪的部位边界框，我们构建了一个感兴趣区域分割网络来生成部位掩模。最后，通过将这些目标部位与第一帧中的视觉信息进行比较，采用基于相似性的评分函数来细化这些目标部位。我们的方法在DAVIS基准数据集的准确性上优于最先进的算法，同时实现更快的运行时性能。

代码：[FAVOS](https://github.com/JingchunCheng/FAVOS)

##### Context-aware Deep Feature Compression for High-speed Visual Tracking

可读性：★★★★★

关键词：目标跟踪，高速

摘要：我们提出了一种新的基于上下文感知的相关滤波器跟踪框架，以实现实时跟踪器之间的高计算速度和最先进的性能。对高计算速度的主要贡献在于所提出的**深度特征压缩**，其通过利用多个专家自动编码器的情境感知方案来实现;我们框架中的上下文是指根据外观模式的跟踪目标的粗略类别。在预训练阶段，每个类别训练一个专家自动编码器。在跟踪阶段，为给定目标选择最佳专家自动编码器，并且仅使用该自动编码器。为了实现压缩特征映射的高跟踪性能，我们引入了外部去噪过程和新的正交性损失项，用于专家自动编码器的预训练和微调。我们通过大量实验来验证所提出的情景感知框架，在这些实验中，我们的方法达到了与不能实时运行的最先进跟踪器相当的性能，同时以超过100 fps的极快速度运行。

项目：[traca-project](https://sites.google.com/site/jwchoivision/home/traca)

##### Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification

可读性：★★★

关键词：行人再识别

摘要：在一个域上训练的行人再识别模型通常不能很好地概括到另一个域。在我们的尝试中，我们提出了一个“通过翻译学习”的框架。在基线中，我们以无监督的方式将标记图像从源域转换为目标域。然后，我们通过监督方法对翻译后的图像进行训练。然而，作为该框架的重要组成部分，无监督图像图像转换在翻译过程中遭受源域标签的信息丢失。我们的动机是双重的。首先，对于每张图片，其ID标签中包含的区分线索应在翻译后保留。其次，考虑到两个领域完全不同的人的事实，翻译后的图片应该与任何目标ID不相同。为此，我们建议保留两种类型的无监督相似性，1）翻译前后的图像的自相似性，以及2）翻译后的源图像和目标图像的域不相似性。这两个约束条件都是在由连体网络和CycleGAN组成的相似性保持生成对抗网络（SPGAN）中实现的。通过域适应实验，我们发现由SPGAN产生的图像更适合于域适应，并且在两个大规模数据集上产生一致且有竞争力的行人再识别准确性。

##### UV-GAN: Adversarial Facial UV Map Completion for Pose-invariant Face Recognition

可读性：★★

关键词：人脸识别，姿态不变性

摘要：最近提出的鲁棒3D人脸对齐方法建立了3D人脸模型和2D人脸图像之间的密集或稀疏对应关系。这些方法的使用带来了新的挑战以及面部纹理分析的机会。特别是，通过使用拟合模型对图像进行采样，可以创建面部UV。不幸的是，由于自闭症，这样的UV图总是不完整的。在本文中，我们提出了一个训练深度卷积神经网络（DCNN）的框架来完成从野外图像中提取的面部UV图。为此，我们首先通过将3D形变模型（3DMM）拟合到各种多视图图像和视频数据集以及利用具有超过3000个身份的新3D数据集来收集完整的UV地图。其次，我们设计了一个精心设计的架构，它结合了本地和全球敌对DCNN来学习保持身份的面部UV完成模型。我们证明，通过将完成的UV附加到拟合的网格并生成任意姿势的实例，我们可以增加姿势变化以训练深度人脸识别/验证模型，并在测试期间最小化姿势偏差，从而提高性能。在受控和野外UV数据集上的实验证明了我们的对抗UV完成模型的有效性。我们通过在训练期间结合姿势增强和在测试期间减少姿势差异来实现CFP前置曲线图协议下的现有验证准确度（94.05％）。我们将发布第一个野外UV数据集（我们称之为WildUV），其中包含1,892个身份的完整面部UV地图用于研究目的。

##### Deep Diffeomorphic Transformer Networks

可读性：★

关键词：数据增强

摘要：至少原则上，空间变换器层允许神经网络对于图像数据中的大空间变换是不变的。 然而，由于大多数实际实施仅支持太受限制的转换，所以该模型看起来受到限制，例如， 仿射图或同形映射图，和/或破坏性图，如薄板样条。 我们研究了在这样的网络中使用灵活的微分变换图像变换，并证明可以在当前使用的模型上获得显着的性能增益。 学到的转换被发现既简单又直观，从而提供对各个问题域的洞察。 利用所提出的框架，标准的卷积神经网络只需两条额外的简单TensorFlow代码就可以匹配面部验证的最新结果。

##### Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation

可读性：★

关键词：场景分割，语义分割

摘要：场景分割是一项具有挑战性的任务，因为它需要标记图像中的每个像素。利用区分性背景和聚合多尺度特征来实现更好的分割至关重要。在本文中，我们首先提出了一种新颖的上下文对比局部特​​征，它不仅利用了信息上下文，而且还聚焦了与上下文相反的局部信息。提出的上下文对比了局部特征，大大提高了解析性能，特别是对于不明显的对象和背景的东西。此外，我们提出门控求和方案来选择性地聚合每个空间位置的多尺度特征。该方案中的门​​控制不同尺度特征的信息流。它们的值由测试图像生成，由建议网络从训练数据中学习，这样它们不仅适应训练数据，而且适应特定的测试图像。没有花里胡哨的工作，所提出的方法在三种流行的场景分割数据集，Pascal上下文，SUN-RGBD和COCO Stuff上实现了一致的SOT水平。

##### Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning

可读性：★★★

关键词：目标跟踪，视觉跟踪

摘要：超参数是数值预设的，其取值是在学习过程开始之前分配的。**选择合适的超参数对于跟踪算法的准确性至关重要，但很难确定它们的最优值，特别是对于每个特定视频序列的自适应参数**。大多数超参数优化算法都依赖于搜索一个通用范围，并且它们被盲目地应用于所有序列。在这里，我们提出了一种新的超参数优化方法，它可以利用连续深度Q学习的动作预测网络为给定序列找到最优超参数。用于目标跟踪任务的公共状态空间比传统控制问题中的复杂得多，所以现有的连续深度Q学习算法不能直接应用。为了克服这个挑战，我们引入了一种有效的启发式方法来加速收敛行为。我们在几个跟踪基准上评估我们的方法，并展示其卓越的性能。

##### Wing Loss for Robust Facial Landmark Localisation with Convolutional Neural Networks

可读性：★★

关键词：人脸关键点检测

摘要：我们提出了一个新的损失函数，即**Wing Loss**，用于利用CNN进行鲁棒的人脸关键点检测。我们首先比较和分析不同的损失函数，包括L2，L1和平滑的L1。对这些损失函数的分析表明，**对基于CNN的模型训练，应该更加关注中小范围的损失**。为此，我们设计了一个分段式损失函数。新损失通过从L1损失切换到修改的对数函数来放大来自间隔（-w，w）的损失的影响。为了解决训练集中具有较大的平面外头部旋转的样本代表性不足的问题，我们提出了一种简单而有效的提升策略，称为基于姿势的数据平衡。特别是，我们通过复制少数训练样本并通过注入随机图像旋转，边界框平移和其他数据增强方法来干扰数据不平衡问题。最后，提出的方法被扩展为创建用于强健人脸关键点检测的两阶段框架。在AFLW和300W上获得的实验结果证明了Wing Loss函数的优点，并且证明了所提出的方法优于最先进的方法的优越性。

代码：[Wing-Loss](https://github.com/FengZhenhua/Wing-Loss)

##### Deep Ordinal Regression Network for Monocular Depth Estimation

可读性：★★★

关键词：单目深度估计

摘要：单目深度估计在理解3D场景几何中起着至关重要的作用，是一个棘手的问题。最近的方法通过探索来自深度卷积神经网络（DCNN）的图像级信息和分层特征而获得显著改善。这些方法将深度估计作为回归问题进行建模，并通过最小化均方误差来训练回归网络，其中收敛缓慢且局部解决方案不令人满意。此外，现有的深度估计网络采用重复的空间池操作，导致不满足需要的低分辨率特征图。为了获得高分辨率深度图，需要跳过连接或多层反卷积网络，这使得网络训练变得复杂并且消耗更多的计算量。为消除或至少在很大程度上减少这些问题，我们引入了一种间距增加离散化（SID）策略来将深度和重铸深度网络学习作为序数回归问题进行离散化。通过使用普通回归损失对网络进行训练，我们的方法实现了更高的准确性和更快的同步收敛。此外，我们采用了多尺度网络结构，避免了不必要的空间合并，并行捕获多尺度信息。所提出的深度顺序回归网络（DORN）在KITTI [16]，Make3D [49]和NYU Depth v2 [41]三个具有挑战性的基准测试中达到了最新的结果，并且其性能优于现有方法余量。

代码：[DORN](https://github.com/hufu6371/DORN)

##### Dynamic Zoom-in Network for Fast Object Detection in Large Images

可读性：★★★★

关键词：目标检测，高分辨率图像

摘要：我们引入了一个通用框架，该框架可降低目标检测的计算成本，同时保持对高分辨率图像中出现大小不同的目标的场景精度。检测以粗到细的方式进行，首先在图像的下采样上，然后在被识别为可能提高检测精度的更高分辨率区域的序列上进行。基于强化学习，我们的方法由一个模型（Rnet）组成，该模型使用粗略检测结果来预测分析较高分辨率区域的潜在准确度增益，以及依次选择要放大的区域的另一个模型（Q-net）。实验在加州理工学院的行人数据集上显示，我们的方法将处理后的像素数量减少了50％以上，检测精度没有下降。我们的方法的优点在从YFCC100M数据集收集的高分辨率测试集中变得更加重要，其中我们的方法保持高检测性能，同时将处理像素数量减少约70％并且检测时间减少超过50％。

##### Detect-and-Track: Efficient Pose Estimation in Videos

可读性：★★★★

关键词：目标跟踪，视觉跟踪

摘要：本文讨论了**在复杂的多人视频中估计和跟踪人体关键点的问题**。我们提出了一种非常轻便但非常有效的方法，它建立在人体检测[17]和视频理解[5]方面的最新进展之上。我们的方法分为两个阶段：帧或短片段中的关键点估计，然后是轻量级跟踪，以生成关联整个视频的关键点预测。对于帧级姿态估计，我们尝试使用Mask R-CNN以及我们自己提出的此模型的3D扩展，该扩展利用小片段上的时间信息来生成更强健的帧预测。我们在新发布的多人视频姿态估计基准PoseTrack上进行了广泛的消融实验，以验证我们模型的各种设计选择。我们的方法使用多目标跟踪精度（MOTA）度量方法实现验证的准确率为55.2％，测试集的准确度为51.8％，并且实现了ICCV 2017 PoseTrack关键点跟踪挑战的最新性能表现。

代码：[DetectandTrack](https://github.com/facebookresearch/DetectAndTrack)

##### DensePose: Dense Human Pose Estimation In The Wild

可读性：★

关键词：行人姿态估计

摘要：在这项工作中，我们建立了RGB图像和基于表面的人体表示之间的密集对应关系，我们称之为**密集人体姿态估计**。通过引入高效的注释管道，我们为出现在COCO数据集中的5万人收集密集对应关系。然后，我们使用我们的数据集来训练基于CNN的系统，这些系统能够在野外提供密集的对应关系，即存在背景，遮挡和尺度变化。我们通过训练一个修复网络来提高我们的训练数据集的有效性，修复网络可以填写缺少的基础真值并报告有关过去可实现的最佳结果的改进。我们试验全卷积网络和区域模型，并观察后者的优越性。我们通过级联进一步提高了准确性，获得了一个系统，可以在单个GPU上以每秒多帧的速度提供高精度的结果。

项目：[DensePose](http://densepose.org/)

##### Efficient and Deep Person Re-Identification using Multi-Level Similarity

可读性：★★★★★

关键词：行人再识别

摘要：行人再识别（ReID）要求比较在不同条件下拍摄的行人的两幅图像。基于神经网络的现有工作通常计算单个卷积层的特征映射的相似性。在这项工作中，我们提出了一个高效的端到端全卷积栾生网络，计算多个层次的相似度。我们证明多级相似性可以在ReID问题中使用低复杂性网络结构大大提高准确性。具体来说，首先，我们使用几个卷积层来提取两个输入图像的特征。然后，我们提出卷积相似性网络来计算输入的相似度分数图。我们使用空间变换网络（STN）来确定空间关注。我们建议应用高效深度卷积来计算相似度。所提出的卷积相似性网络可以被插入不同的卷积层以提取不同级别的视觉相似性。此外，我们使用改进的排名损失来进一步提高性能。我们的工作是首次提出计算ReID的低，中，高级视觉相似度。通过广泛的实验和分析，我们证明我们的系统紧凑而有效，可以通过更小的模型尺寸和计算复杂性来实现竞争结果。

##### A Twofold Siamese Network for Real-Time Object Tracking

可读性：★★★★★

关键词：实时目标跟踪

摘要：由于观察到在图像分类任务中学习到的语义特征和在相似匹配任务中学习到的外观特征相互补充，我们构建了一个名为SA-Siam的双重连接网络，用于实时目标跟踪。SA-Siam由语义分支和外观分支组成。每个分支都是一个相似学习的栾生网络。SA-Siam的一个重要设计是分别训练两个分支以保持两种特征的异质性。另外，我们提出了语义分支的渠道关注机制。通道权重根据目标位置周围的通道激活进行计算。虽然SiamFC的继承体系结构允许我们的跟踪器实时运行，但双重设计和关注机制显着提高了跟踪性能。在OTB-2013/50/100基准测试中，拟议的SA-Siam优于所有其他实时跟踪器。

##### Deep Spatial Feature Reconstruction for Partial Person Re-identification: Alignment-free Approach

可读性：★★★

关键词：行人再识别

摘要：行人再识别是一个具有挑战性的问题，只有几个人的部分观察（图像）可用于匹配。然而，**很少有研究提供灵活的解决方案来识别包含身体任意部分的图像中的人**。在本文中，我们提出了一种快速而准确的匹配方法来解决这个问题。所提出的方法利用全卷积（FCN）生成固定尺寸的空间特征图，使得像素级特征一致。为了匹配一对不同尺寸的人物图像，进一步开发了称为深空间特征重建（DSR）的新方法以避免明确对齐。具体来说，DSR利用流行字典学习模型中的重构误差来计算不同空间特征地图之间的相似度。通过这种方式，我们预计所提出的FCN可以减少来自不同人的耦合图像的相似性并且增加来自同一个人的图像的相似性。关于两个遮挡行人数据集的实验结果证明了与几种现有技术的行人再识别方法相比，所提出的方法的效率和有效性。此外，DSR在基准人数数据集Market1501上获得了具有83.58％Rank-1准确度的竞争结果。

代码：[Code](https://github.com/lingxiao-he/Deep-Spatial-Feature-Reconstruction-for-Partial-Person-Re-identification)

##### Dynamic Feature Learning for Partial Face Recognition

可读性：★★★

关键词：人脸识别

摘要：**部分人脸识别（PFR）在无约束的环境中是一项非常重要的任务**，尤其是在视频监控，移动设备等方面。然而，一些研究已经解决了如何识别人脸图像的任意块。本研究将全卷积（FCN）与稀疏表示分类（SRC）相结合，提出了一种称为动态特征匹配（DFM）的新型局部人脸识别方法，以解决部分人脸图像无论大小如何。基于DFM，我们提出了一种滑动损失优化FCN的方法，通过减少面片和人脸图像之间的内部变化，进一步提高了DFM的性能。所提出的DFM在几个遮挡人脸数据库上进行评估，包括LFW，YTF和CASIA-NIR-Distance数据库。实验结果证明了DFM与最先进的PFR方法相比的有效性和优势。

##### Improving Landmark Localization with Semi-Supervised Learning

可读性：★

关键词：人脸关键点检测

摘要：我们提出了两种技术来提高部分注释数据集图像中的关键点定位。我们的主要目标是利用普通情况，即精确的关键点定位仅为小数据子集提供，但与关键点相关的分类或回归任务的类别标签更丰富。首先，我们提出顺序多任务处理框架，并通过关键点定位架构在这里探索它，其中类别标签的训练作为辅助信号来指导未标记数据的关键点定位。我们方法的一个关键方面是可以通过完整的关键点定位模型反向传播误差。其次，我们提出并探索了一种基于模型预测等效关键点与应用于图像变换的关键点定位的无监督学习技术。我们表明，这些技术，大大改善关键点定位效果，并可以学习有效的检测器，即使只有一小部分数据集具有关键点的标签。我们将结果显示在两个模拟数据集和四个真实数据集上，包括手和脸部，并在野外的两个数据集上报告最新的最新技术。只有5％的标记图像胜过了先前在AFLW数据集上进行的最先进的训练。

##### Learning to Segment Every Thing

可读性：★

关键词：实例分割

摘要：大多数用于对象实例分割的方法都要求用分割掩模来标记所有训练示例。这个要求使得注释新的类别变得很昂贵，并且将实例分割模型限制在大约100个注释良好的类中。本文的目标是提出一种新的部分监督训练范式，以及一种新颖的权重传递函数，它能够对大量类别中的训练实例分割模型进行训练，所有这些类别都有框注释，但只有一小部分具有框注释掩码注释。通过这些贡献，我们可以训练Mask R-CNN使用Visual Genome数据集中的框注释和COCO数据集中80个类的掩码注释来检测和分割3000个视觉概念。我们在COCO数据集的对照研究中评估我们的方法。这项工作是对具有广泛理解视觉世界的实例细分模型的第一步。

##### Relation Networks for Object Detection

可读性：★★★★

关键词：目标检测关联网络

摘要：尽管多年来人们相信，目标之间的建模关系有助于对象识别，但还没有证据表明这个想法在深度学习时代有效。所有最先进的目标检测算法仍然依赖于单独识别目标实例，而不需要在学习期间利用它们之间的关系。这项工作提出了一个目标关系模块。它通过外观特征和几何图形之间的相互作用同时处理一组目标，从而允许建立它们之间的关系。它权重数量少并且是内嵌的。它不需要额外的监督，并且很容易嵌入现有网络。在现代物体检测流水线中，它对改善物体识别和清除重复步骤有效。它验证了建模目标关系在基于CNN的检测中的功效。它产生了第一个完全端对端的目标检测器。

##### Squeeze-and-Excitation Networks（SENet）

可读性：★★

关键词：网络结构

摘要：卷积神经网络建立在卷积运算的基础上，通过融合本地感受域内的空间信息和信道信息来提取信息特征。为了提高网络的表现能力，最近的几种方法已经显示出增强空间编码的好处。在这项工作中，我们关注通道关系并提出了一种新颖的架构单元，我们称之为“挤压和激励”（SE）模块，通过显式建模通道之间的相关性来自适应重新校准通道特征响应。我们证明，通过将这些块堆叠在一起，我们可以构建SENet体系结构，在具有挑战性的数据集中进行非常好的泛化。至关重要的是，我们发现SE块以最小的额外计算成本为现有技术的深层架构产生显着的性能改进。SENets组成了我们ILSVRC 2017分类提交的基础，赢得了第一名，并将top-5的误差显著降低至2.251％，与2016年的获胜者相比，获得了约25％的相对改进。

代码：[SENet](https：// github.com/hujie-frank/SENet)

##### Pointwise Convolutional Neural Networks

可读性：★★★★

关键词：点云卷积，语义分割，目标识别

摘要：3D数据的深度学习，如重建点云和CAD模型，近来获得了极大的研究兴趣。然而，卷积神经网络使用点云的能力还没有完全探索。在本文中，我们提出了一个用于三维点云的语义分割和对象识别的卷积神经网络。我们网络的核心是逐点卷积，一种新的卷积算子，可应用于点云的每个点。我们的全卷积网络设计虽然实现起来非常简单，但却可以在**语义分割和对象识别任务**中产生有竞争力的准确性。

代码：[PCNN](https://github.com/scenenn/pointwise)

##### Adversarially Occluded Samples for Person Re-identification

可读性：★

关键词：行人再识别

摘要：行人再识别（ReID）是通过不同摄像头检索特定人员的任务。尽管近年来取得了长足的进步，但它仍然面临着**姿势变化，遮挡以及不同人物之间相似外观等挑战**。训练和测试性能与现有模型之间的巨大差距意味着泛化的不足。考虑到这个事实，我们建议通过引入对抗遮挡样本来增加训练数据的变化。这些特殊样本是a）有意义的，因为它们类似于真实场景遮挡，并且b）有效，因为它们对于原始模型是艰难的，因此提供跳出局部最优的动力。我们根据训练有素的ReID模型和网络可视化技术的帮助来挖掘这些样本。大量的实验表明，所提出的样本可以帮助模型发现身体上新的区分线索，并在测试时更好地推广。我们的战略在三个大型ReID数据集Market1501，CUHK03和DukeMMC-reID的强基线方面做出了重大改进。

##### CondenseNet: An Efficient DenseNet using Learned Group Convolutions

可读性：★★★★

关键词：网络结构，紧凑型网络

摘要：深度神经网络越来越多地用于计算资源有限的移动设备。在本文中，我们开发了具有前所未有的效率的新型网络架构CondenseNet。它将密集连接与称为学习群组卷积的新模块相结合。密集的连通性有利于网络中的特征重用，而学习的群组卷积消除了该特征重复使用的层之间的连接是多余的。在测试时，我们的模型可以使用标准组卷积来实现，从而在实践中实现高效的计算。我们的实验表明CondenseNets比ShuffleNets等最先进的紧凑卷积网络更有效率。

代码：[CondenseNet](https://github.com/ShichenLiu/CondenseNet)

##### LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation

可读性：★★★★★

关键词：光流估计

摘要：用于光流估计的最先进的卷积神经网络（CNN）FlowNet2需要超过**160M的参数**才能实现精确的流量估计。在本文中，我们提出了一个替代网络，该网络在具有挑战性的Sintel最终通过和KITTI基准测试中获得与FlowNet2相同的性能，同时**模型尺寸缩小30倍，运行速度提高1.36倍**。这可以通过深入到当前框架中可能错过的架构细节来实现：（1）我们通过轻量级联网络在每个金字塔等级提供更有效的流量推断方法。它不仅通过早期修正提高了流量估计的准确性，而且还允许在我们的网络中无缝并入描述符匹配。（2）通过使用特征驱动的局部卷积，我们提出了一种新颖的流动正则化层来改善异常值和模糊流动边界的问题。（3）我们的网络拥有用于金字塔特征提取的有效结构，并且包含了FlowNet2中实现的特征翘曲而非图像翘曲。

代码：[LiteFlowNet](https://github.com/twhui/LiteFlowNet)

##### Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference

可读性：★★

关键词：模型优化压缩，量化

摘要：智能移动设备的日益普及以及基于深度学习的模型的巨大计算成本要求高效且准确的设备推断方案。 我们提出了一种量化方案，它允许使用整数运算来进行推理，该算法可以比通常可用的纯整数硬件上的浮点推断更有效地实现。我们还共同设计了一个训练过程来保留量化后的端对端模型精度。 结果，所提出的量化方案改善了准确度和器件上等待时间之间的折衷。即使在运行时效率较高的模型系列MobileNets上，这些改进也很有意义，并且在流行CPU上的ImageNet分类和COCO检测中得到了演示。

##### Human Semantic Parsing for Person Re-identification

可读性：★★★

关键词：行人再识别

摘要：行人再识别是一项具有挑战性的任务，主要是由于诸如**背景噪声，姿势，照明和相机角度变化等因素**。这些元素阻碍了提取鲁棒性和区分性表示的过程，从而阻止了不同身份被成功区分。为了改善**表示学习**，通常提取人体部位的局部特征。但是，这种过程的通常做法是基于边界框部分检测。在本文中，**我们建议采用人为语义分析**，由于其像素级精度和建模任意轮廓的能力，自然是更好的选择。我们提出的SPReID将人类语义解析集中在行人再识别中，不仅显著优于其基线，而且实现了最先进的性能。我们还表明，通过采用简单而有效的训练策略，流行的深度卷积网络结构（如Inception-V3和ResNet-152）在不进行修改的情况下，仅在完整映像下运行时，可以大大超越当前的最新技术水平。我们提出的方法将最先进的行人再识别性能进行了提升：Market-1501 [48]的mAP提升约17％，rank-1提升约6％，CUHK03 [24]的rank-1提升约4％，DukeMMC-reID [50]的mAP提升约24％，rank-1提升约10％。

##### Learning Structure and Strength of CNN Filters for Small Sample Size Training

可读性：★

关键词：小样本训练，新生儿人脸识别

摘要：卷积神经网络在几个计算机视觉问题中提供了最先进的结果。然而，由于CNN中有大量的参数，它们需要大量的训练样本，这是小样本量问题的限制因素。为了解决这个限制，我们提出了SSF-CNN，它侧重于学习滤波器的“结构”和“强度”。滤波器的结构使用基于字典的滤波器学习算法来初始化，并且使用小样本训练数据来学习滤波器的强度。该架构提供了小规模和大规模培训数据库的培训灵活性，即使小规模训练数据也能产生良好的精确度。该算法的有效性首先在MNIST，CIFAR10和NORB数据库上展示，并且具有不同数量的训练样本。结果表明，SSF-CNN显着减少了训练所需参数的数量，同时在测试数据库上提供了高精度。对于像新生儿脸部识别和Omniglot这样的小样本大小问题，它会产生最先进的结果。具体而言，在IIITD新生儿脸部数据库中，结果显示等级1识别准确度提高至少10％。

##### NestedNet: Learning Nested Sparse Structures in Deep Neural Networks

可读性：★★★★

关键词：模型压缩，剪枝

摘要：最近，构建紧凑的深层体系结构以消除不必要的冗余并提高推理速度的需求日益增加。尽管最近的许多工作着重于通过消除不必要的重量参数来减少冗余，但不可能为具有不同资源的多个设备应用单个深度网络。当新设备或情况条件需要新的深层架构时，有必要从头开始构建和培训一个新网络。在这项工作中，我们提出了一种新型的深度学习框架，称为嵌套稀疏网络，它利用神经网络中的n合1型嵌套结构。嵌套稀疏网络由多级网络组成，每个级别具有不同的稀疏比率，而较高级别的网络与较低级别的网络共享参数以实现稳定的嵌套学习。所提出的框架实现了资源感知的多功能体系结构，因为相同的网络可以满足不同的资源需求，即任何时间属性。此外，所提出的嵌套网络可以在不同级别的内部网络中学习不同形式的知识，从而使得使用单一网络的多任务成为可能，例如从粗到精的分层分类。为了训练提出的嵌套网络，我们提出了有效的权重连接学习和信道和层调度策略。我们评估我们的网络的多个任务，包括**自适应深度压缩，知识蒸馏和学习类层次结构**，并演示与现有方法相比，嵌套稀疏网络具有竞争性但更高效的性能。

##### Analyzing Filters Toward Efficient ConvNet

可读性：★★★★

关键词：滤波器的分析

摘要：深度卷积神经网络是用于高性能图像分类的有前途的方法。ConvNet的行为主要基于神经元激活进行分析，例如通过观察它们。在本文中，与激活相比，我们专注于作为ConvNets主要组件的过滤器。通过分别在各种预先训练的ConvNets上的卷积和完全连接（FC）层分析两种类型的滤波器，我们提出了有效地重构滤波器的方法，有助于提高ConvNets的内存大小和分类性能。它们呈现了无参数形式的滤波器基础以及FC层的高效表示。图像分类的实验结果表明，这些方法有利于改进各种ConvNets，包括ResNet，在ImageNet上训练，在其他数据集上表现出高可转移性。

##### CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes

可读性：★★★★★

关键词：拥堵检测

摘要：我们提出了一个称为CSRNet的**拥塞场景识别网络**，它提供了一种数据驱动和深度学习方法，可以**理解高度拥挤的场景**并**执行准确的计数估计**以及**高质量的密度图**。提议的CSRNet由两个主要部分组成：作为2D特征提取前端的卷积神经网络（CNN）和用于后端的扩展CNN，其使用扩大的内核来提供更大的接收场并取代池化操作。由于其纯粹的卷积结构，CSRNet是一个易于训练的模型。我们在四个数据集（ShanghaiTech数据集，UCF CC 50数据集，WorldEXPO'10数据集和UCSD数据集）上展示CSRNet，并提供最先进的性能。在ShanghaiTech B部分数据集中，CSRNet的平均绝对误差（MAE）比以前的方法降低了47.3％。我们扩展了用于计算其他对象（如TRANCOS数据集中的车辆）的目标应用程序。结果显示，CSRNet比先前的先进方法显着提高了MAE的输出质量，降低了15.4％。

##### Diversity Regularized Spatiotemporal Attention for Video-based Person Re-identification

可读性：★★

关键词：行人再识别

摘要：基于视频的行人再识别与非重叠摄像机上行人的视频剪辑匹配。大多数现有方法通过对每个视频帧进行完整编码并计算跨所有帧的聚合表示来解决此问题。在实践中，人们常常部分被遮挡，这会破坏提取的特征。相反，我们提出了一种新的时空关注模型，可以自动发现多种独特的身体部位。这允许从所有帧中提取有用的信息而不会屈服于遮挡和未对齐。该网络学习多个空间关注模型并采用多样性正则化术语来确保多个模型不会发现相同的身体部分。从局部图像区域提取的特征由空间关注模型组织，并且使用时间关注进行组合。因此，网络使用整个视频序列中的最佳可用图像补丁来学习脸部，躯干和其他身体部位的潜在表示。对三个数据集的广泛评估表明，我们的框架在多个指标上大幅超越了最先进的方法。

##### Harmonious Attention Network for Person Re-Identification

可读性：★★★★

关键词：行人再识别

摘要：现有的行人重识别（re-id）方法要么假定可以将准确对齐的人的边界框图像作为模型输入，要么依靠受限的注意力选择机制来校准未对准的图像。因此，它们对于任意对齐的人物图像中的重新匹配是次优的，潜在地具有大的人体姿势变化和无约束的自动检测错误。在这项工作中，我们展示了联合学习卷积神经网络（CNN）中的注意力选择和特征表示的优点，通过最大化不同级别的视觉注意力的补充信息受到重新识别学习约束的影响。具体而言，我们制定了一种新的和谐注意力CNN（HA-CNN）模型，用于联合学习软像素注意力和硬区域注意力，并同时优化特征表示，致力于优化未控制（未对齐）图像中的人员重新识别。广泛的比较评估验证了这个新的HACNN模型在包括CUHK03，Market-1501和DukeMMC-ReID在内的三个大型基准测试中对各种最先进的方法进行人员再认的优越性。

##### High Performance Visual Tracking with Siamese Region Proposal Network

可读性：★★★

关键词：目标跟踪

摘要：视觉对象追踪一直是近年来的一个基本话题，许多基于深度学习的跟踪器已经在多个基准上取得了最先进的性能。但是，大多数这些追踪器很难以实时速度获得最佳性能。在本文中，我们提出了连续训练与大规模图像对离线训练的Siamese地区推选网络（Siamese-RPN）。具体来说，它包括用于特征提取的栾生网络和包括分类分支和回归分支的区域推选网络。在推理阶段，提出的框架被制定为本地一次性检测任务。我们可以预先计算连体子网络的模板分支，并将相关层作为平凡的卷积层来执行在线跟踪。从提案细化中受益，传统的多尺度测试和在线微调可以被丢弃。Siamese-RPN以160 FPS运行，同时实现VOT2015，VOT2016和VOT2017实时挑战的领先性能。

##### Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking

可读性：★★★

关键词：目标跟踪

摘要：鉴别相关滤波器（DCF）在视觉追踪中是有效的，但遭受不需要的边界效应。已经提出空间正则化DCF（SRDCF）来通过对DCF系数执行空间惩罚来解决该问题，这不可避免地通过增加复杂度改善了跟踪性能。为了处理在线更新，SRDCF在多个训练图像上制定了模型，进一步增加了提高效率的难度。在这项工作中，通过将单个样本的时间正则化引入SRDCF，我们提出了空间时间正则化相关滤波器（STRCF）。 STRCF公式不仅可以作为SRDCF与多个训练样本的合理近似，而且在外观变化大的情况下也可以提供比SRDCF更强大的外观模型。此外，它可以通过乘法器的交替方向法（ADMM）有效解决。通过结合时间和空间正则化，我们的STRCF可以处理边界效应，而不会产生太多的效率损失，并且在精确度和速度方面比SRDCF实现更好的性能。与SRDCF相比，具有手工特征的STRCF提供了5倍加速，分别在OTB-2015和Temple-Color上获得了5.4％和3.6％的AUC分数。此外，具有深度特征的STRCF对于最先进的跟踪器也表现出色，并且在OTB-2015上获得了68.3％的AUC评分。

代码：[STRCF](https://github.com/lifeng9472/STRCF)

##### A Prior-Less Method for Multi-Face Tracking in Unconstrained Videos

可读性：★★★★

关键词：多张人脸检测与跟踪

摘要：本文提出了一种用于跟踪和聚类未知数量人脸并在无约束的视频中保持其ID的方法。关键的挑战是准确跟踪面部部分遮挡和由于化妆，面部表情，头部姿势和照明的显着变化而引起的多个镜头剧烈外观变化。为了解决这个挑战，我们提出了一种新的多人脸跟踪和重新识别算法，该算法在整个视频中提供了高精度的脸部关联，并且具有自动生成群号的功能，并且对异常值很有效。我们开发了多个身体部位的共现模型，以无缝地创建人脸轨迹，并递归链接轨迹以构建提取群集的图形。引入高斯过程模型来补偿深度特征不足，并进一步用于细化链接结果。提出的算法的优点通过使用各种具有挑战性的音乐视频和新推出的身穿相机视频来演示。所提出的方法在现有技术水平上得到显着改善[51]，同时更少地依靠处理视频特定的先验信息来实现高性能。

##### DecideNet: Counting Varying Density Crowds Through Attention Guided Detection and Density Estimation

可读性：★★

关键词：密集人群估计

摘要：在现实世界的人群计数应用中，人群密度在时间和空间上差异很大。基于检测的计数方法将在低密度场景中精确估计人群，同时在拥挤区域的可靠性降低。另一方面，基于回归的方法捕捉拥挤地区的一般密度信息。不知道每个人的位置，往往会高估低密度地区的人数。**因此，仅使用它们中的任何一个都不足以处理具有不同密度的所有类型的场景**。为了解决这个问题，提出了一种名为DecideNet（DEteCtIon and Density Estimation Network）的新型端到端人群统计框架。它可以根据实际密度条件自适应地决定图像上不同位置的适当计数模式。 DecideNet首先通过分别生成基于检测和回归的密度图来估计人群密度。为了捕捉不可避免的密度变化，它包含了一个注意模块，旨在适应性地评估这两种估计的可靠性。在注意力模块的引导下获得最终的人群数量，以从两种密度图中采用合适的估计。实验结果表明，我们的方法在三个具有挑战性的人群计数数据集上实现了最先进的性能。

##### Disentangling Features in 3D Face Shapes for Joint Face Reconstruction and Recognition

可读性：★

关键词：3D人脸识别

摘要：本文提出了一种编码器-解码器网络，用于从单个2D图像中解开三维人脸重建过程中的形状特征，从而可以同时完成重建精确三维人脸形状和学习识别形状特征的任务。与现有的三维人脸重建方法不同，我们提出的方法直接从单个二维图像中回归密集的三维人脸形状，并基于复合三维人脸形状模型明确地分别处理三维人脸形状中的身份和残差（即非同一性）潜在的表示。我们针对所提出的网络设计了训练过程，其具有测量脸部识别误差和3D脸部形状重建误差的联合损失。为了构建训练数据，我们开发了一种将3D形变模型（3DMM）拟合到对象的多个2D图像的方法。 MICC，BU3DFE，LFW和YTF数据库已经完成了全面的实验。结果表明，我们的方法扩展了3DMM的能力，以捕捉判别形状特征和面部细节，因此在3D人脸重建精度和人脸识别精度方面都优于现有方法。

##### Learning Deep Models for Face Anti-Spoofing: Binary or Auxiliary Supervision

可读性：★

关键词：活体检测

摘要：面相防伪对防止面部识别系统出现安全漏洞至关重要。以前的深度学习方法将面部反欺骗描述为二元分类问题。他们中的许多人都在努力去抓住足够的欺骗线索，并且总结得很差。在本文中，我们认为辅助监督的重要性在于引导学习走向歧视性和一般化的线索。学习CNN-RNN模型以逐像素监测来估计面部深度，并且通过顺序监测来估计rPPG信号。估计的深度和rPPG被融合以区分现场和欺骗面孔。此外，我们引入了一个新的面部反欺骗数据库，涵盖了大范围的照明，主题和姿势变化。实验表明，我们的模型在数据库内和跨数据库测试中实现了最新的结果。

##### Leveraging Unlabeled Data for Crowd Counting by Learning to Rank

可读性：★

关键词：密集人群估计

摘要：我们提出了一种新颖的人群计数方法，该方法在学习到排名框架中利用大量可用的未标记人群图像。为了引起裁剪图像的排序，我们使用以下观察：拥挤的场景图像的任何子图像被保证包含与超图像相同数量或更少的人。这使我们能够解决现有数据集大小有限的人群计数问题。我们分别使用关键字搜索和查询示例图像检索从Google收集两个人群场景数据集。我们演示了如何通过将学习到排名并入多任务网络中，从而同时对图像进行排名并估计人群密度图，从而有效地从这些未标记的数据集中学习。对两个最具挑战性的人群计数数据集进行的实验表明，我们的方法获得了最先进的结果。

##### Mobile Video Object Detection with Temporally-Aware Feature Maps

可读性：★★★★

关键词：视频目标检测

摘要：本文介绍了一种在线视频中的对象检测模型，旨在实时运行低功耗移动和嵌入式设备。我们的方法将快速单图像对象检测与卷积长短期记忆（LSTM）层相结合，以创建交织循环卷积体系结构。此外，与常规LSTM相比，我们提出了一个高效的Bottleneck-LSTM层，可显著降低计算成本。我们的网络通过使用Bottleneck-LSTM改进和传播帧间的特征映射来实现时间意识。这种方法比视频中的现有检测方法快得多，在模型尺寸和计算成本方面优于最快的单帧模型，同时获得与Imagenet VID 2015数据集上更昂贵的单帧模型相当的精度。我们的模型在移动CPU上实现高达15 FPS的实时推断速度。

##### Path Aggregation Network for Instance Segmentation

可读性：★

关键词：聚合网络，实例分割

摘要：信息在神经网络中传播的方式非常重要。在本文中，我们提出路径聚合网络（PANet），旨在提高基于提案的实例分割框架中的信息流。具体来说，我们通过自下而上的路径增强在较低层中使用精确的定位信号来增强整个特征层次，这缩短了较低层和最顶层特征之间的信息路径。我们提出了自适应特征池，它将链接特征网格和所有特征级别，以使每个级别的有用信息直接传播到以下提议子网络。为每个提案捕获不同视图的补充分支被创建以进一步改善掩模预测。这些改进很容易实现，具有微妙的额外计算开销。然而，它们非常有用，使我们的PANET在COCO 2017挑战实例分段任务中排名第一，在对象检测任务中排名第二，无需大批量训练。PANET也是MVD和Cityscapes的最新技术。

##### Pose Transferrable Person Re-Identification

可读性：★★★

关键词：Re-ID

摘要：行人再识别（ReID）是智能安全领域的一项重要任务。一个关键的挑战是**如何捕捉人体姿势的变化**，而现有的基准（即Market1501，DukeMMC-reID，CUHK03等）不提供足够的姿势覆盖范围来训练鲁棒的ReID系统。为了解决这个问题，我们提出了一个可迁移行人ReID框架，该框架利用了姿态迁移的样本增强（比如，ID监督的）来增强ReID模型的训练。一方面，通过从MARS数据集中传递姿态实例，生成具有丰富姿态变化的新训练样本，并将它们添加到目标数据集中以促进强大的训练。另一方面，除了常规的GAN鉴别器（即区分REAL / FAKE样本）之外，我们还提出了一种新的导向器子网络，该网络鼓励生成的样本（即以新姿势）更好地满足ReID损失（即交叉熵ReID损失，三重态ReID损失）。同时，提出了另一种优化程序来训练所提出的Generator-Guider-Discriminator网络。Market-1501，DukeMMC-reID和CUHK03的实验结果表明，我们的方法实现了很好的性能改进，并且在没有精心设计ReID模型的情况下胜过了大多数最先进的方法。

##### Robust Facial Landmark Detection via a Fully-Convolutional Local-Global Context Network

可读性：★

关键词：人脸关键点检测

摘要：尽管完全卷积神经网络在建模局部特征方面非常强大，但由于其受限制的接受范围，它们无法聚合全局范围。现代方法通常通过引入级联，汇集或拟合统计模型来解决缺乏全球背景。在这项工作中，我们提出了一种将全局上下文直接引入全卷积神经网络的新方法。关键概念是网络中的隐式内核卷积。内核卷积模糊本地上下文子网的输出，然后使用扩展卷积通过全局上下文子网对其进行改进。内核卷积对于网络的收敛至关重要，因为它平滑了渐变并减少了过度拟合。在后处理步骤中，将一个简单的基于PCA的二维形状模型拟合到网络输出中，以过滤异常值。我们的实验证明了我们的方法的有效性，超过了几种最先进的面部标志物检测方法。

##### Direct Shape Regression Networks for End-to-End Face Alignment

可读性：★★★★★

关键词：人脸对齐

摘要：人脸对齐在计算机视觉领域已经被广泛研究，因为它在面部分析中起着重要作用，但它仍然是一个未解决的问题。主要挑战在于人脸图像和相关面部形状之间的高度非线性关系，这通过地标的基础关联进行耦合。**现有方法主要依赖于级联回归，其具有固有的缺点，例如，对初始化的强依赖性和未利用关键点之间的相关性**。在本文中，我们提出了直接形状回归网络（DSRN）进行端到端人脸对齐，通过在统一框架中共同处理上述挑战。具体而言，通过部署双卷积层和本文提出的傅立叶特征池层，DSRN有效地构造强表示以解决图像和形状之间的高度非线性关系;通过整合低秩学习的线性层，DSRN有效地编码地标的相关性以提高性能。 DSRN利用内核在非线性特征提取和神经网络结构预测方面的优势，为直接人脸对齐提供了首个端到端学习架构。通过对五个基准数据集进行广泛的实验，验证其有效性和一般性，其中包括AFLW，300W，CelebA，MAFL和300VW。所有的实证结果都表明，DSRN始终如一地产生出高性能，并且在大多数情况下超越了最先进的技术。

##### Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors

可读性：★★★★★

关键词：行人检测

摘要：我们提出了解决行人检测两个关键问题的方法：（i）将目标物体遮挡当作假阴性问题;（ii）将像垂直结构这样的硬阴性样本混淆为假阳性问题。我们对这两个问题的解决方案通用且灵活，足以适用于任何单级检测模型。我们将我们的方法实现为四个最先进的单阶段模型，包括SqueezeDet+ [22]，YOLOv2 [17]，SSD [12]和DSSD [8]。我们凭经验验证了我们的方法确实提高了这四种模型在Caltech行人[4]和CityPersons数据集[25]上的性能。此外，在一些重度遮挡设置中，我们的方法实现了最佳的报告性能。具体来说，我们的两个解决方案如下。为了更好地进行遮挡处理，我们更新单阶段模型的输出张量，以便它们包括部分置信度分数的预测，从中我们计算最终的遮挡感知检测分数。为了减少与硬性负面样本的混淆，我们引入平均网格分类器作为后期细化分类器，可以以端到端方式进行培训，而且存储器和时间开销很小（例如，内存中增加1-5MB，内存中增加1-2MB，推理时间）。

##### Mean-Variance Loss for Deep Age Estimation from a Face

可读性：★★

关键词：年龄估计

摘要：年龄估计在视频监控，社交网络和人机交互中有广泛的应用。许多已发表的方法将年龄估计简单地视为一个确定的年龄回归问题，因此不利用分布的鲁棒性来表示具有模糊性（如年龄）的标签。在本文中，我们提出了一种新的损失函数，称为**均值-方差损失**，用于通过分布式学习进行鲁棒的年龄估计。具体而言，均值-方差损失包括平均损失，该平均损失惩罚估计的年龄分布的平均值和地面实况年龄之间的差异，以及方差损失，其惩罚估计的年龄分布的方差以确保集中分布。所提出的均值方差损失和softmax损失共同嵌入到卷积神经网络（CNN）中用于年龄估计。在FG-NET，MORPH Album II，CLAP2016和AADB数据库上的实验结果表明，所提出的方法大大优于最先进的年龄估计方法，并很好地用于图像美学评估。

##### MegDet: A Large Mini-Batch Object Detector

可读性：★★★★

关键词：目标检测

摘要：从R-CNN [11]，Faster R-CNN [10,31]到最近的Mask R-CNN [14]和RetinaNet [24]，深度学习时代目标检测的发展主要来自新网络，新框架或损失函数的设计。然而，mini-batch size是深度神经网络训练的关键因素，对于目标检测尚未得到很好的研究。在本文中，我们提出了一个大型mini-batch目标检测器（MegDet），使大型mini-batch的训练能够达到256，这样我们就可以有效地利用最多128个GPU来显著缩短训练时间。从技术上讲，我们建议采用预热学习速率策略和跨GPU批量标准化，这使我们能够在更短的时间内（例如，从33小时到4小时）成功训练大型mini-batch检测器，并实现更高的准确性。 MegDet是我们提交COCO 2017 Challenge的主要内容（mmAP 52.5％），我们赢得了第一个检测任务。

##### Deep Reinforcement Learning of Region Proposal Networks for Object Detection

可读性：★★★

关键词：目标检测

摘要：我们提出drl-RPN，一个深度强化学习型视觉识别模型，由连续区域提议网络（RPN）和目标检测网络组成。与典型的RPNs相比，通过类别不可知的NMS贪婪地选择候选目标区域（RoIs），drlRPN优化了一个更接近最终检测任务的目标。这是通过用深度强化学习（RL）训练的顺序注意力机制取代贪婪的RoI选择过程来实现的。我们的模型能够随着时间积累特定类别的证据，可能影响随后的提案和分类评分，并且我们显示这种背景整合显着提高了检测的准确性。此外，drl-RPN自动决定何时停止搜索过程，并且能够共同学习策略和探测器的参数，这两个参数均表示为深度网络。我们的模型可以进一步学习在多种勘探精度折衷方面进行搜索，从而可以在测试时指定或调整勘探范围。最终的搜索轨迹是图像和类别相关的，但仅依赖于所有对象类别的单一策略。 MS COCO和PASCAL VOC挑战的结果表明，我们的方法优于已建立的，典型的最先进的目标检测框架。

##### Data Distillation: Towards Omni-Supervised Learning

可读性：已读

关键词：数据蒸馏

摘要：我们研究全方位监督学习，这是一种半监督学习的特殊形式，其中学习者利用所有可用的标记数据加上未标记数据的互联网规模来源。全监督学习受现有标签数据集性能的限制，有可能超越最先进的全监督方法。为了利用全方位监督设置，我们提出了数据蒸馏，一种使用单一模型集成来自多个未标记数据变换的预测的方法，以自动生成新的训练注释。我们认为视觉识别模型最近已经足够准确，现在可以将关于自我训练的经典观点应用于具有挑战性的现实世界数据。我们的实验结果表明，在人类关键点检测和一般目标检测的情况下，用数据蒸馏进行训练的最先进的模型超过了单独使用来自COCO数据集的标记数据的性能。

##### Fusing Crowd Density Maps and Visual Object Trackers for People Tracking in Crowd Scenes

可读性：★★★

关键词：目标跟踪，人群密度图

摘要：虽然近年来视觉跟踪已经大大改善，但由于严重的闭塞，高人群密度和显着的外观变化，人群场景对于人们追踪仍然特别具有挑战性。为了解决这些挑战，我们首先设计一个稀疏核化相关滤波器（S-KCF）来抑制由遮挡和光照变化引起的目标响应变化，以及由于类似的干扰物对象引起的虚假响应。然后，我们提出一个人员跟踪框架，使用卷积神经网络（CNN）将SKCF响应图与估计的人群密度图相融合，从而生成精确的响应图。为了训练CNN融合，我们提出了一个两阶段策略来逐步优化参数。第一阶段是以批处理模式训练初步模型，在目标周围选择图像块，第二阶段是使用真实的逐帧跟踪过程微调初步模型。我们的密度融合框架可以显着改善人群场景中的人物跟踪，还可以与其他跟踪器结合使用以提高跟踪性能。我们在两个人群视频数据集上验证我们的框架。

##### Features for Multi-Target Multi-Camera Tracking and Re-Identification

可读性：★★★★

关键词：目标跟踪，Re-ID

摘要：多目标多相机跟踪（MTMCT）通过从多个相机拍摄的视频中跟踪多个人。行人重识别（Re-ID）从图库中检索与人类查询图像相似的人的图像。我们通过卷积神经网络学习MTMCT和Re-ID的良好特征。我们的贡献包括用于训练的自适应加权三元组丢失和用于硬标识挖掘的新技术。我们的方法超越了DukeMTMC跟踪基准以及Market-1501和DukeMTMC-ReID等Re-ID基准测试的技术水平。我们检查了良好的Re-ID和良好MTMCT评分之间的相关性，并进行消融研究以阐明我们系统主要组成部分的贡献。

##### Exploiting Transitivity for Learning Person Re-identification Models on a Budget

可读性：★

关键词：Re-ID，数据标注

摘要：由于大多数现有流行方法都是受监督的，并且他们需要大量的手工注释，因此是一项繁琐的工作，所以最大限度地减少相机网络中的行人重识别标注工作是一个重要问题。**在这项工作中，我们关注这个标记工作量最小化问题，并将其作为一个子集选择任务来处理，其目标是选择一个用于标记而不影响性能的图像对的最佳子集**。为了实现这一目标，我们提出的方案首先将任何摄像机网络（具有k个摄像机）表示为边缘加权完整k-部分图，其中每个顶点表示人并且人之间的相似度得分被用作边缘权重。然后在第二阶段，我们的算法通过求解k-partite图上的三角形自由子图最大化问题来选择最佳的对子集。该子图权重最大化问题是NP难的（至少对于k≥4），这意味着对于大数据集，优化问题变得难以处理。为了使我们的框架具有可伸缩性，我们提出了两个多项式时间近似最优算法。第一种算法是在边数中以线性时间运行的1/2逼近算法。第二种算法是具有亚二次方（边数）复杂度的贪婪算法。对三种最新数据集的实验表明，所提出的方法平均只需8-15％的手动标记对，以便在手动标注所有对时实现性能。

##### MobileNetV2: Inverted Residuals and Linear Bottlenecks

可读性：已读

关键词：目标分类，目标检测

摘要：在本文中，我们描述了一种新的移动架构MobileNetV2，它可以改善移动模型在多个任务和基准以及不同模型尺寸范围内的最新性能。我们还描述了在我们称之为SSDLite的新框架中将这些移动模型应用于对象检测的有效方法。此外，我们还演示了如何通过简化形式的DeepLabv3（我们称之为Mobile DeepLabv3）构建移动语义分段模型。基于快速连接位于薄瓶颈层之间的倒转残差结构。中间展开层使用轻量级的深度卷积来过滤作为非线性源的特征。此外，我们发现为了保持代表性的能力，去除窄层中的非线性是非常重要的。我们证明这可以提高性能并提供导致这种设计的直觉。最后，我们的方法允许输入/输出域与转换的表达性分离，这为进一步分析提供了方便的框架。我们测量了ImageNet [1]分类，COCO目标检测[2]，VOC图像分割[3]的性能。我们评估准确性与乘法加法（MAdd）测量的操作次数，实际延迟和参数数量之间的权衡。

##### A Pose-Sensitive Embedding for Person Re-Identification with Expanded Cross Neighborhood Re-Ranking

可读性：★★★★

关键词：行人再识别，Re-ID

摘要：行人再识别是一项具有挑战性的检索任务，需要在非重叠的摄像机视图中匹配人的获取图像。在本文中，我们提出了一种有效的方法，它结合了人的精细和粗略姿势信息来学习判别嵌入。与最近基于这些明确建模身体部位或校正未对准的方向相反，我们表明将获得的相机视图和/或检测到的关节位置相当直接地包含到卷积神经网络中有助于学习非常有效的表示。为了提高检索性能，基于计算距离的重新排序技术最近引起了很多关注。我们提出了一种新的无监督和自动重新排序框架，该框架实现了最先进的重新排名性能。我们表明，与当前最先进的重新排序方法相比，我们的方法不需要为每个图像对计算新的排名列表（例如，基于互惠邻居）并且通过使用简单的直接排名列表表现的比基于比较或甚至仅仅使用已经计算的图像之间的欧氏距离要良好一些。我们展示了我们的学习表现和我们的重新排名方法在许多具有挑战性的监控图像和视频数据集上实现了最先进的性能。

代码：[PSE-ECN](https://github.com/pse-ecn)

##### Deep Group-shuffling Random Walk for Person Re-identification

可读性：★★★

关键词：行人再识别，Re-ID

摘要：行人重识别旨在通过将目标人物的图像与所有图库图像进行比较来找到图像库中感兴趣的人物。它通常被视为检索问题，其中目标图像和图库图像（P2G亲和度）之间的亲和度用于对检索到的图库图像进行排序。然而，大多数现有方法仅考虑P2G亲和力，但忽略所有图库图像之间的亲和性（G2G亲和力）。一些框架将G2G的亲和力纳入测试过程中，这对于深度神经网络来说不是端到端的可训练的。在本文中，我们提出了一种新的群组随机游走网络，充分利用图像图像在训练和测试过程中的亲和力信息。所提出的方法旨在通过简单而有效的矩阵运算来基于G2G亲和度信息端到端地改进P2G亲和力，其可以集成到深度神经网络中。还提出了特征分组和组合洗牌，以应用丰富的监督学习更好的人物特征。所提出的方法在Market1501，CUHK03和DukeMTMC数据集上的表现优于大型利润，这证明了我们的方法的有效性。

##### Deep Regression Forests for Age Estimation

可读性：★★★★

关键词：年龄估计

摘要：来自面部图像的年龄估计通常被视为非线性回归问题。这个问题的主要挑战是面部特征空间w.r.t.年龄不均匀，这是由于同一年龄段不同人的面部外观差异很大，以及衰老模式的非平稳性。在本文中，我们提出了**深度回归森林（DRFs）**，一种端到端模型，用于年龄估计。DRF将分离节点连接到卷积神经网络（CNN）的全连接层，并通过在分离节点处联合学习输入相关数据分区和叶节点处的数据抽象来处理非均匀数据。该联合学习遵循交替策略：首先，通过修复叶节点，通过反向传播来优化分裂节点以及CNN参数;然后，通过修复拆分节点，通过迭代从变分边界导出的步长自由更新规则来优化叶节点。我们在三个标准年龄估算基准上验证了提议的DRF，并在所有这些基准上取得了最新的成果。

##### Deep Semantic Face Deblurring

可读性：★

关键词：人脸去模糊

摘要：在本文中，我们通过深度卷积神经网络（CNNs）利用语义线索提出了一种有效且高效的人脸去模糊算法。由于面部图像是高度结构化的并且共享若干关键语义成分（例如，眼睛和嘴巴），因此面部的语义信息为恢复提供了强大的先验。因此，我们建议将全局语义先验作为输入并且施加局部结构损失以在多尺度深度CNN内规范化输出。我们通过感知和对抗性损失训练网络，以生成照片般逼真的结果，并开发增量训练策略来处理野外随机模糊核心。定量和定性评估表明，所提出的面部去模糊算法恢复具有更多面部细节的清晰图像，并且在恢复质量，面部识别和执行速度方面对于最先进的方法有利地执行。

##### End-to-End Deep Kronecker-Product Matching for Person Re-identification

可读性：★★★

关键词：行人再识别，Re-ID

摘要：行人再识别旨在稳健地测量行人图像之间的相似性。人体姿势和视角的显着变化是准确的行人再识别的挑战。查询行人图像之间的空间布局和对应关系是解决此问题的重要信息，但大多数最先进的方法都忽略了这些信息。在本文中，我们提出了一种新颖的Kronecker产品匹配模块，以匹配端到端可训练深度神经网络中不同人员的特征图。一种新颖的特征软翘曲方案被设计用于基于匹配结果对准特征图，这被证明对于实现高精度是至关重要的。基于沙漏状网络和自残注意的多尺度特征也被用于进一步提高重新识别性能。所提出的方法优于Market-1501，CUHK03和DukeMTMC数据集上的最新方法，这些方法证明了我们提出的方法的有效性和泛化能力。

##### Crowd Counting with Deep Negative Correlation Learning

可读性：★

关键词：人群密度估计

摘要：卷积网络（ConvNets）在许多计算机视觉任务中取得了前所未有的性能。然而，他们对单一图像人群的适应仍处于起步阶段，并且严重过度。在这里，我们提出了一种新的学习策略，通过深度负相关学习（NCL）来产生可概括的特征。更具体地说，我们通过管理其内在的多样性，深入学习了一系列具有良好泛化能力的去相关回归量。我们提出的方法，称为解相关的ConvNet（D-ConvNet），是端到端可训练的，并且独立于主干全卷积网络架构。在非常深的VGGNet以及我们的定制网络结构上进行的大量实验表明，与几种最先进的方法相比，D-ConvNet具有优越性。

代码：[Deep-NCL](https://github.com/shizenglin/Deep-NCL)

##### Dual Attention Matching Network for Context-Aware Feature Sequence based Person Re-Identification

可读性：★★★★

关键词：行人再识别，Re-ID

摘要：典型的行人再识别（ReID）方法通常用单个特征向量描述每个行人，并在特定于任务的度量空间中匹配它们。然而，基于单个特征向量的方法不足以克服视觉模糊，这在实际场景中经常发生。在本文中，我们提出了一种新的端到端可训练框架，称为双重匹配网络（DuATM），用于学习上下文感知特征序列并同时进行细致的序列比较。我们的DuATM框架的核心组件是双重注意机制，其中序列内和序列间关注策略分别用于特征细化和特征对对齐。因此，可以自动利用并适当地比较中间特征序列中包含的详细视觉提示。我们将拟议的DuATM网络作为栾生网络进行训练，通过三重损失辅助解相关丢失和交叉熵损失。我们对基于图像和视频的ReID基准数据集进行了大量实验。与最先进的方法相比，实验结果证明了我们方法的显着优点。

##### An Analysis of Scale Invariance in Object Detection – SNIP

可读性：★★★★★

关键词：目标检测

摘要：提出了在极端尺度变化下识别和检测物体的不同技术的分析。通过使用不同的输入数据配置训练检测器的比例特定和比例不变设计。通过评估不同网络架构在ImageNet上对小对象进行分类的性能，我们发现CNN对规模变化不稳健。基于此分析，我们建议在图像金字塔的相同尺度上训练和测试探测器。由于小尺寸和大尺寸的物体很难分别在更小和更大的尺度上识别，因此我们提出了一种称为图像金字塔（Scale Pyramids，SNIP）的尺度标准化的新型训练方案，该方案选择性地将作为图像的函数的不同尺寸的对象实例的梯度规模。在COCO数据集上，我们的单一模型性能为45.7％，3个网络的集合获得48.3％的mAP。我们使用现成的ImageNet-1000预训练模型，仅使用边界框监控进行训练。我们的提交获得了COCO 2017挑战赛中的最佳学生参赛资格。

代码：[SNIP](https://github.com/bharatsingh430/snip)

##### R-FCN-3000 at 30fps: Decoupling Detection and Classification

可读性：★★★

关键词：目标检测

摘要：我们提出了一种通过解耦目标检测和分类来实现大规模实时目标检测的模块化方法。我们利用了许多对象类在视觉上相似并共享部分的事实。因此，可以学习通用目标检测器用于类别不可知对象检测，然后使用（非）线性分类器进行细粒度分类。我们的方法是修改R-FCN架构，以学习用于跨不同对象类执行本地化的共享过滤器。我们为3000个对象类训练了一个名为R-FCN3000的探测器，它在ImageNet探测数据集上获得了34.9％的mAP。它在处理每秒30幅图像时优于YOLO-9000 18％。 我们还表明，R-FCN-3000学习的对象性推广到新的类，并且性能随着训练对象类的数量而增加 - 支持可以学习通用对象检测器的假设。

##### Beyond Trade-off: Accelerate FCN-based Face Detector with Higher Accuracy

可读性：★★★

关键词：目标检测，人脸检测

摘要：全卷积（FCN）已经在人脸检测任务中占据了主导地位，其具有先天的共享内核滑动窗口搜索功能，这使得所有冗余计算失效，并且如Faster-RCNN，SSD，YOLO和FPN使用FCN作为其主干。所以这里有一个问题：我们能否找到一种通用策略来更高精度地进一步加速FCN，那么可以加速所有最近基于FCN的方法吗？为了分析这一点，我们将人脸搜索空间分解为两个正交方向，即“比例”和“空间”。由两个基矢量扩展的空间中只有几个坐标表示前景。因此，如果FCN可以忽略大多数其他点，搜索空间和误报应该显着降低。基于这一理念，提出了一种新的方法 - 尺度估计和空间注意提议，以关注图像金字塔中的某些特定尺度和每个尺度层的有效位置。此外，我们采用基于注意结果的掩蔽卷积运算来加速FCN计算。实验表明，基于FCN的方法RPN在$S^2AP$和掩蔽FCN的帮助下可以加速约4倍，同时它也可以实现FDDB，AFW和MALF人脸检测的最新技术基准也是如此。

##### Mask-guided Contrastive Attention Model for Person Re-Identification

可读性：★★★★

关键词：行人再识别，Re-ID

摘要：行人再识别（ReID）是计算机视觉中一项重要且具有挑战性的任务。由于各种背景杂乱，观点和身体姿势的变化，它远未解决。如何提取对背景杂乱不变的判别和鲁棒特征是核心问题。在本文中，我们首先介绍二进制分割掩模来构造合成的RGB-Mask对作为输入，然后我们设计一个掩模引导的对比注意模型（MGCAM）来学习与身体和背景区域分开的特征。此外，我们提出了一种新颖的区域级三联体损失，以限制从不同区域学习的特征，即，从完整图像和身体区域拉近特征，而从背景推动特征。我们可能是第一个成功将二元掩模引入人ReID任务的人，也是第一个提出区域级对比学习的人。我们在三个公共数据集上评估所提出的方法，包括MARS，Market-1501和CUHK03。大量实验结果表明，该方法是有效的，并达到了最先进的结果。面具和代码将根据要求发布。

##### VITAL: Visual Tracking via Adversarial Learning

可读性：★★★★

关键词：目标跟踪

摘要：逐个检测框架包括两个阶段，即在第一阶段中围绕目标对象绘制样本并将每个样本分类为目标对象或在第二阶段中将其分类为背景。使用深度分类网络的现有跟踪器的性能受到两方面的限制。首先，每帧中的阳性样本在空间上高度重叠，并且它们不能捕获丰富的外观变化。其次，正负样本之间存在极端的等级不平衡。本文介绍了通过对抗学习解决这两个问题的VITAL算法。为了增加阳性样本，我们使用生成网络随机生成掩模，将其应用于自适应丢失输入特征以捕捉各种外观变化。通过使用敌对学习，我们的网络可以识别在长时间跨度上保持目标对象最稳健特征的蒙版。此外，为了处理类不平衡问题，我们提出了一种高订单成本敏感性损失，以减少容易负样本的影响，以便于训练分类网络。对基准数据集进行的大量实验表明，所提议的跟踪器对最先进的方法有良好的表现。

代码：[VITAL](https://github.com/ybsong00/Vital_release)

##### Correlation Tracking via Joint Discrimination and Reliability Learning

可读性：★★★

关键词：目标跟踪

摘要：对于视觉跟踪，通过相关滤波器（CF）方法学习的理想滤波器应该同时采用鉴别和可靠性信息。然而，现有的尝试通常集中于前者，而对可靠性学习的关注较少。这可能使得学习的滤波器由特征图上的意外显着区域支配，从而导致模型退化。为了解决这个问题，我们提出了一种新的基于CF的优化问题来联合建模歧视和可靠性信息。首先，我们将滤波器视为基本滤波器和可靠性项的元素乘积。基础过滤器旨在了解目标和背景之间的区分信息，可靠性术语鼓励最终过滤器专注于更可靠的区域。其次，我们引入了局部响应一致性常规术语，以强调不同区域的平等贡献，并避免跟踪器被不可靠区域控制。所提出的优化问题可以使用交替方向方法来解决并且在傅里叶域中加速。我们在OTB-2013，OTB-2015和VOT-2016数据集上进行了大量实验，以评估提出的跟踪器。实验结果表明，我们的跟踪器对其他最先进的跟踪器表现出色。

##### Learning Spatial-Aware Regressions for Visual Tracking

可读性：★★★★

关键词：目标跟踪

摘要：在本文中，我们分析了深度特征的空间信息，并提出两个互补的回归鲁棒视觉跟踪。首先，我们提出了核化岭回归模型，其中核值被定义为两个样本之间的所有补丁对的相似性得分的加权和。我们表明，这个模型可以被制定为一个神经网络，因此可以有效地解决。其次，我们提出了一个具有空间正则化核的完全卷积神经网络，通过该核心，对应于每个输出通道的滤波器核被强制聚焦在目标的特定区域上。 进一步利用距离变换池来确定卷积层的每个输出通道的有效性。将核心岭回归模型和完全卷积神经网络的输出结合起来以获得最终响应。两个基准数据集的实验结果验证了该方法的有效性。

##### High-speed Tracking with Multi-kernel Correlation Filters

可读性：★★★

关键词：目标跟踪

摘要：基于相关滤波器（CF）的跟踪器目前在其性能方面排名第一。然而，只有其中一些，如KCF [26]和MKCF [48]，能够利用非线性内核的强大可辨性。虽然MKCF通过将多内核学习（MKL）引入KCF实现了比KCF更强大的可辨性，但是它对KCF的改进非常有限，并且与KCF相比其计算负担显着增加。在本文中，我们将以与MKCF不同的方式将MKL引入KCF。我们以其上限重构了CFL目标函数的MKL版本，显著减轻了不同内核的负相互干扰。我们的新型MKCF跟踪器MKCFup的表现优于KCF和MKCF，并且仍能以非常高的fps工作。对公共数据集的大量实验表明，我们的方法优于最先进的算法，用于高速移动的小移动目标对象。

##### High-speed Tracking with Multi-kernel Correlation Filters

可读性：★★★

关键词：目标跟踪

摘要：基于相关滤波器（CF）的跟踪器目前在其性能方面排名第一。然而，只有其中一些，如KCF [26]和MKCF [48]，能够利用非线性内核的强大可辨性。虽然MKCF通过将多内核学习（MKL）引入KCF实现了比KCF更强大的可辨性，但是它对KCF的改进非常有限，并且与KCF相比其计算负担显着增加。在本文中，我们将以与MKCF不同的方式将MKL引入KCF。我们以其上限重构了CFL目标函数的MKL版本，显著减轻了不同内核的负相互干扰。我们的新型MKCF跟踪器MKCFup的表现优于KCF和MKCF，并且仍能以非常高的fps工作。对公共数据集的大量实验表明，我们的方法优于最先进的算法，用于高速移动的小移动目标对象。