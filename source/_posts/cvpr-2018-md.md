---
title: CVPR2018论文整理
date: 2018-06-13 13:45:23
categories: 资料汇总
tags:
     - resources
---
##### Learning Pixel-level Semantic Affinity with Image-level Supervision for Weakly Supervised Semantic Segmentation

关键词：弱监督训练，语义分割

摘要：为了解决分割标签制作的低效率问题，文章提出了一个新的框架，**根据图像级别的类别标签生成图像的语义标签**。在这种弱监督环境中，我们知道训练过的模型可以分割局部区域而不是整个物体区域。我们的方法是将这种本地响应传播到属于同一语义整体的相邻区域。为此，我们提出一个叫做AffinityNet的深度神经网络用于预测一对相邻图像坐标之间的语义亲和度。然后，通过AffinityNet预测亲和性随机游走来实现语义传播。更重要的是，用来训练AffinityNet的监督信号是由初始判别性部分分割给出的，它作为分割标注来说是不完全的，但是足够学习小图像区域内的语义亲和度。因此，整个框架仅仅依赖于图像级的类别标注，并不需要额外数据或标注。在VOC2012数据集上，使用我们方法生成的分割标注学习的DNN效果优于之前用相同监督水平训练的模型，甚至与那些依赖强监督的模型相比也是具有竞争力的。

##### A PID Controller Approach for Stochastic Optimization of Deep Networks

可读性：★★★

关键词：训练优化方法，PID控制

摘要：深度神经网络已经在许多计算机视觉应用中证明了它们的能力，如VGG，ResNet和DenseNet之类的最先进的模型主要通过SGD-Momentum算法进行优化，该算法通过考虑过去和当前的梯度来更新权重。尽管如此，**SGD-Momentum仍存在超调问题**，阻碍了网络训练的融合。受自动控制中PID控制器成功的启发，我们提出了一种用于加速深度网络优化的PID方法。我们首先揭示了SGD-Momentum和基于PID的控制器之间的内在联系，然后介绍利用过去，当前和梯度变化来更新网络参数的优化算法。**所提出的PID方法大大减少了SGD-Momentum的过冲现象**，并且通过我们对基准数据集（包括CIFAR10，CIFAR100和Tiny-ImageNet）的实验验证，它可以在具有竞争精度的DNN架构上实现高达50％的加速。

代码：[PIDOptimizer](https://github.com/tensorboy/PIDOptimizer)

备注：PID控制的思想引入到模型训练的随机优化过程，据说效果不错，但是主要优点在与可以加速训练收敛的速度，有空可以自己跑一下代码试试。

##### Finding Tiny Faces in the Wild with Generative Adversarial Network

关键词：人脸检测，生成对抗网络

摘要：人脸检测技术已经发展了数十年，其中一个尚未解决的挑战是**在无约束的条件下检测小脸**。原因是**微小的脸部往往缺乏详细的信息和模糊**。在本文中，我们提出了一种算法，通过采用生成对抗网络（GAN），从模糊的小模型直接生成清晰的高分辨率人脸。基本的GAN通过超分辨率和精细化（例如SR-GAN和cycle-GAN）来实现。但是，我们设计了一个新颖的网络来解决超解决和共同提炼的问题。我们还引入了新的训练损失，以指导发生器网络恢复细节，并促使鉴别器网络同时区分真假和脸部/非脸部。在具有挑战性的数据集WIDER FACE上进行的大量实验证明我们提出的方法能够从一个模糊的小图像恢复清晰的高分辨率人脸，并显示其检测性能优于其他最先进的方法。

##### The power of ensembles for active learning in image classification

可读性：★★

关键词：主动学习

摘要：深度学习方法已成为挑战图像处理任务（如图像分类）的事实标准。深度学习方法的一个主要障碍是需要大量的标记数据，这可能会导致昂贵的成本，特别是在医学图像诊断应用中。**主动学习技术**可以缓解这种标签工作。在本文中，我们研究一些最近提出的用于高维数据和卷积神经网络分类器的主动学习方法。我们比较了基于集合的方法与蒙特卡洛压差和几何方法。我们发现集成表现更好，并导致更多校准的预测不确定性，这是许多主动学习算法的基础。为了调查为什么蒙特卡罗辍学不确定性表现更差，我们在一系列实验中探索了孤立性的潜在差异。我们展示了MNIST和CIFAR-10的结果，其中我们用大约12,200个标记图像获得了90％的测试集精度，并在ImageNet上获得了初始结果。此外，我们在大型高度不平衡的糖尿病性视网膜病变数据集上展示结果。我们观察到，基于集成的主动学习方法有效地抵消了不平衡的影响。

备注：介绍了主动学习和集成学习相结合的方法。

##### Dense Decoder Shortcut Connections for Single-Pass Semantic Segmentation

可读性：★★

关键词：语义分割，Dense Decoder

摘要：我们提出了一种**用于单通道语义分割的新型端到端可训练深度编码器解码器架构**。我们的方法基于具有功能级远程跳过连接的级联架构。该编码器结合了ResNeXt残差构建模块的结构，并采用重复构建模块的策略，该构建模块汇总了具有相同拓扑的一组变换。该解码器具有一种新颖的架构，由块组成，这些架构包括（i）捕获上下文信息，（ii）生成语义特征，以及（iii）实现不同输出分辨率之间的融合。至关重要的是，我们引入了密集的解码器快捷连接，以允许解码器块使用来自所有先前解码器级别的语义特征映射，即来自所有更高级别的特征映射。密集的解码器连接允许从一个解码器块到另一个解码器块的有效信息传播，以及多级特征融合，从而显着提高准确性。重要的是，这些连接使我们的方法能够在几个具有挑战性的数据集上获得最先进的性能，而不需要之前多尺度工作那样的平均耗时。

##### Cascade R-CNN: Delving into High Quality Object Detection

可读性：★★★★★

关键词：级联R-CNN，目标检测

摘要：在目标检测中，需要通过IoU阈值来定义正例和负例。用低IoU阈值进行训练的目标检测器，如0.5，通常会产生嘈杂的检测结果。但是，**IoU阈值增加后检测性能会降低**。造成这种情况的原因有两个：1）正样本太少会导致训练过拟合；2）推理时间不匹配。本文提出了级联检测算法Cascade R-CNN用于解决这些问题。它由一系列IoU阈值增加而训练的检测器组成，以对接近的假阳性依次更具有选择性。目标检测器逐步进行训练，利用观测器的输出是一个良好的分布来训练下一个更高质量的目标检测器。逐步改进假设的重采样从而保证所有目标检测器都有一组正确的等效大小样本，减少过拟合的情况。在部署中应用相同的级联结构，使得假设和每个阶段的目标检测器质量之间更接近匹配。级联R-CNN的简单实现超过COCO数据集上所有单模型目标检测器。实验还表明，级联R-CNN可广泛应用于不同的目标检测器架构，获得与基准检测器强度无关的一致增益。

代码：[Cascade R-CNN](https://github.com/zhaoweicai/cascade-rcnn)

备注：R-CNN的级联结构，应该是高分辨率图像中目标检测算法的趋势。

##### Deep Cauchy Hashing for Hamming Space Retrieval

关键词：图像检索，哈希编码

摘要：哈希算法由于其计算效率和检索质量，已被广泛应用于近似最近邻搜索的大规模图像检索，而深度哈希通过端到端表示学习和哈希编码进一步提高了检索质量。通过紧凑的散列码，海明空间检索可实现最有效的恒定时间搜索，该搜索可通过散列表查找而不是线性扫描将给定汉明半径内的数据点返回给每个查询。然而，由于错误指定的损失函数，将相关图像集中在小海明球内的能力较弱，现有的深度哈希方法可能会因海明空间检索而表现不佳。这项工作提出了Deep Cauchy Hashing（DCH），这是一种新颖的深度哈希模型，可生成紧凑且集中的二进制哈希代码，从而实现高效的海明空间检索。其主要思想是设计一个基于柯西分布的成对交叉熵损失，在海明距离大于给定的汉明半径阈值的情况下，对相似图像对产生显著的惩罚。综合实验表明，DCH可以生成高度集中的散列码，并在三个数据集NUS-WIDE，CIFAR-10和MS-COCO上产生最先进的海明空间检索性能。

##### HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN

关键词：图像检索，哈希编码

摘要：深度哈希通过端对端表示学习和来自具有成对相似性信息的训练数据的哈希编码来改善图像检索性能。由于相似性信息的稀缺性对于许多应用领域来说通常很昂贵，所以现有的对哈希方法的深度学习可能过度训练数据并导致检索质量的显著损失。本文介绍了HashGAN，一种用于深入学习哈希的新颖体系结构，它从真实图像和由生成模型合成的各种图像学习紧凑二进制哈希码。其主要思想是增加训练数据，用几乎真实的图像合成一个新的Pair Conditional Wasserstein GAN（PC-WGAN）条件成对相似性信息。大量实验表明，HashGAN可以生成高质量的二进制散列码，并在NUS-WIDE，CIFAR-10和MS-COCO三个基准测试中获得最先进的图像检索性能。

##### Partially Shared Multi-Task Convolutional Neural Network with Local Constraint for Face Attribute Learning

可读性：★★★

关键词：人脸属性识别

摘要：在本文中，我们同时考虑身份信息和属性关系来研究人脸属性的学习问题。具体而言，我们首先引入部分共享多任务卷积神经网络（PS-MCNN），其中四个任务专用网络（TSNets）和一个共享网络（SNet）通过部分共享（PS）结构连接以学习更好的共享和任务特定的表示。为了利用身份信息来进一步提高性能，我们引入了局部学习约束，该约束将每个样本与其具有相同身份的局部几何领域的表示之间的差异最小化。因此，我们提出了一个局部约束正规化的多任务网络，称为局部共享多任务卷积神经网络与局部约束（PS-MCNNLC），其中PS结构和局部约束集成在一起，以帮助框架学习更好的属性表示。CelebA和LFWA的实验结果证明了所提出方法的前景

##### Pose-Robust Face Recognition via Deep Residual Equivariant Mapping

可读性：★★★★★

关键词：人脸识别

摘要：由于深度学习的出现，人脸识别取得了非凡的成功。然而，与正面相比，许多当代人脸识别模型在处理人脸时仍然表现较差。**一个关键的原因是正面和侧面训练面孔的数量高度不平衡**。与侧面训练样本相比，正面训练样本更多。此外，从本质上来说，**很难学习一个对于大姿态变化下具有几何不变性的深度表示**。在本研究中，我们假设前面和侧面之间存在固有的映射关系，因此它们在深度表示空间中的差异可以通过等变映射来弥补。为了利用这种映射，我们制定了一种新颖的深度残差等熵映射（DREAM）块，它能够自适应地将残差添加到输入深度表示中，**以将剖面人脸表示转换为简化识别的典型姿态**。DREAM模块不断加强许多强大深度网络（包括ResNet模型）的轮廓人脸识别性能，而不会有意增加轮廓面的训练数据。该模块易于使用，重量轻，并且可以用可忽略的计算开销1来实现。

代码：[DREAM](https://github.com/penincillin/DREAM)

备注：[中文解读](http://www.sohu.com/a/225437836_129720)

##### “Learning-Compression” Algorithms for Neural Net Pruning

可读性：★★★

关键词：剪枝，模型压缩，模型优化

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

##### Deep Spatio-Temporal Random Fields for Efficient Video Segmentation

可读性：★★

关键词：视频分割

摘要：修剪神经网络包括去除权重而不降低其性能。这是一个重新引起兴趣的老问题，因为需要压缩更大的网络，以便它们可以在移动设备上运行。传统上通过按照某些标准（如数量级）对权重进行排名或惩罚，删除排名低的权重并重新训练剩余的权重来修剪。我们制定修剪作为优化问题，在满足剪枝成本条件的同时找到最小化损失的权重。我们给出一个通用的算法来解决这个问题，它交替“优化正则化的数据相关损失”的“学习”步骤和标记权重的“压缩”步骤，以便以独立于数据的方式进行修剪。幅度阈值在压缩步骤中自然出现，但与现有的幅度修剪方法不同，我们的算法探索权重的子集，而不是不可避免地从一开始就对特定的子集进行提交。它也能够自动学习最佳数量的权重以修剪网络的每一层，而不会产生指数级的昂贵模型选择。使用单个pruning level用户参数，我们在LeNet和ResNets中实现了各种大小的最新修剪。

代码：[gcrf](https://github.com/siddharthachandra/gcrf)

##### Multi-Level Factorisation Net for Person Re-Identification

可读性：★★★★

关键词：行人再识别

摘要：有效的行人再识别（Re-ID）的关键是**在高和低的语义层次上对行人外观的区别性和视角不变因素进行建模**。最近开发的深度Re-ID模型**要么学习整体单一语义级别的特征表示和/或需要这些因素的费力的人类注释作为属性**。我们提出了**多层次因子网（MLFN）**，这是一种新颖的网络架构，可将人的视觉外观在多种语义层次上分解为潜在的判别因子，无需人工注释。MLFN由多个堆叠块组成。每个块包含多个因子模块以模拟特定级别的潜在因子，因子选择模块动态选择因子模块以解释每个输入图像的内容。因子选择模块的输出还提供了一个紧凑的潜在因子描述符，它与传统的深度学习特征相辅相成。MLFN在三个Re-ID数据集上实现了最先进的结果，并在通用对象分类CIFAR-100数据集上获得了令人瞩目的结果。

##### Pyramid Stereo Matching Network

可读性：★★★

关键词：双目深度估计

摘要：最近的研究表明，从一对立体图像进行深度估计可以被制定为一个监督学习任务，用卷积神经网络（CNN）来解决。然而，目前的体系结构依赖于基于补丁的连体网络，缺乏利用上下文信息来找到在所示区域的对应关系的手段。为了解决这个问题，我们提出PSMNet，一个由两个主要模块组成的金字塔立体匹配网络：空间金字塔池和3D-CNN。空间金字塔池模块通过聚合不同尺度和位置的上下文来利用全局上下文信息的能力来调整惩罚量。3D-CNN学习使用堆叠的多个沙漏网络结合中间监督来调整惩罚量。所提出的方法在几个基准数据集上进行了评估。 我们的方法在2018年3月18日之前的KITTI 2012和2015排行榜中排名第一。

代码：[PSMNet](https://github.com/JiaRenChang/PSMNet)

##### Cascaded Pyramid Network for Multi-Person Pose Estimation

可读性：★

关键词：多人姿态估计，关键点检测

摘要：多人姿态估计近年来得到了很大的改善，特别是随着卷积神经网络的发展。然而，仍然存在很多具有挑战性的案例，例如**闭塞的关键点，不可见的关键点和复杂的背景**，这些都不能很好地解决。在本文中，我们提出了一种称为级联金字塔网络（CPN）的新型网络结构，其目标是从这些“硬”关键点解决问题。更具体地说，我们的算法包括两个阶段：GlobalNet和RefineNet。GlobalNet是一个功能金字塔网络，可以成功定位像眼睛和手这样的“简单”关键点，但可能无法准确识别被遮挡或不可见的关键点。我们的RefineNet试图通过集成GlobalNet的所有级别的特征表示以及在线硬关键点挖掘损失来明确处理“硬”关键点。通常，为了解决多人姿态估计问题，采用自顶向下的管线首先根据检测器生成一组人类边界框，然后在每个人体边界框中用CPN进行关键点定位。基于所提出的算法，我们在COCO关键点基准测试中获得了最先进的结果，COCO测试开发数据集的平均精度为73.0，COCO测试挑战数据集的平均精度为72.1，与60.5相比，相对提高了19％来自COCO 2016关键挑战。 Code1以及所使用人员的检测结果将公开发布供进一步研究。

代码：[CPN](https://github.com/chenyilun95/tf-cpn)

##### Deep Hashing via Discrepancy Minimization

关键词：哈希编码，图像检索

摘要：本文提出了一个差异最小化模型来解决**哈希学习中的离散优化问题**。二元约束引入的离散优化是一个NP难混合整数规划问题。通常通过将二进制变量放宽为连续变量来适应基于梯度的哈希函数学习，特别是深度神经网络的训练。针对松弛引起的客观差异，将原始二元优化问题转化为哈希函数可微分优化问题。该变换将二进制约束和相似性保持散列函数优化解耦。转换后的目标在一个易处理的交替优化框架中进行了优化，并逐步减少了差异。在三个基准数据集上的广泛实验结果验证了所提出的差异使散列最小化的有效性。

##### Group Consistent Similarity Learning via Deep CRF for Person Re-Identification

可读性：★★★

关键词：行人再识别

摘要：行人再识别从深度神经网络（DNN）中获益很多，以学习精确的相似性度量和强健的特征嵌入。然而，目前大多数方法仅对相似性学习施加局部约束。在本文中，我们将CRF与深度神经网络相结合，将大型图像组的约束纳入其中。所提出的方法旨在学习成对图像的“局部相似性”度量，同时考虑组中所有图像的相关性，形成“组相似性”。我们的方法涉及多个图像来模拟训练期间统一CRF中局部和全局相似性之间的关系，同时结合多尺度局部相似性作为测试中的预测相似性。我们采用近似推理方案来估计组相似性，从而实现端到端的培训。大量的实验证明了我们的模型的有效性，它结合了DNN和CRF来学习稳健的多尺度局部相似性。整体结果优于那些在三个广泛使用的基准上具有相当利润率的艺术家。

##### MaskLab: Instance Segmentation by Refining Object Detection with Semantic and Direction Features

可读性：★

关键词：实例分割

摘要：在这项工作中，我们解决了实例分割的问题，同时解决了对象检测和语义分割的任务。为了实现这个目标，我们提出了一个名为MaskLab的模型，它产生三个输出：box检测，语义分割和方向预测。建立在Faster-RCNN对象检测器之上，预测框提供了对象实例的精确定位。在每个感兴趣的区域内，MaskLab通过结合语义和方向预测来执行前景/背景分割。语义分割帮助模型区分包括背景在内的不同语义类别的对象，而方向预测（估计每个像素朝向其相应中心的方向）允许分离相同语义类别的实例。此外，我们还探讨了从分段和检测（例如，卷积和超列）中整合最新成功方法的效果。我们提出的模型在COCO实例细分基准上进行评估，并与其他最先进的模型进行比较。

##### Progressively Complementarity-aware Fusion Network for RGB-D Salient Object Detection 

可读性：★★★★

关键词：RGB-D，深度摄像头，目标检测

摘要：**如何充分结合跨模式互补是RGB-D显著物体检测的基石问题**。以前的作品主要通过简单地连接多模态特征或结合单峰预测来解决这个问题。在本文中，我们从两个角度回答了这个问题：（1）我们认为，如果互补部分可以更明确地建模，那么跨模态补充可能会被更好地捕获。为此，我们在采用卷积神经网络（CNN）时设计了一种新型互补感知融合（CA-Fuse）模块。通过在每个CA-Fuse模块中引入交叉模态残差函数和互补意识监督，从成对模态中学习补充信息的问题被明确提出为渐近逼近残差函数。（2）探索各个层面的补充。通过级联CA-Fuse模块并添加从深层到深层的层级式监管，可以选择并逐步组合跨层次补充。所提出的RGB-D融合网络消除了跨模态和跨层次融合过程的歧义，并能够获得更充分的融合结果。公共数据集上的实验显示了所提出的CA-Fuse模块和RGB-D显着物体检测网络的有效性。

##### Optimizing Video Object Detection via a Scale-Time Lattice

可读性：★★★

关键词：视频目标检测

摘要：高性能对象检测依赖于昂贵的卷积网络来计算特征，这经常导致应用中的重大挑战，例如，那些需要实时从视频流中检测对象的应用程序。这个问题的关键是以有效的方式交换效率的准确性，即在保持竞争性能的同时降低计算成本。**为了寻求一个良好的平衡，以前的努力通常集中于优化模型架构**。本文探讨了另一种方法，即重新分配一个尺度空间的计算。基本思想是稀疏地执行昂贵的检测，并通过大量廉价的网络，通过利用它们之间的强相关性，在大小和时间上传播结果。具体而言，**我们提出了一个统一的框架，将检测，时间传播和跨尺度精细化整合到一个Scale-Time格中**。在此框架中，可以探索各种策略来平衡性能和成本。利用这种灵活性，我们进一步开发一种自适应方案，并根据需要调用检测器，从而获得改进的折衷。在ImageNet VID数据集中，所提出的方法可以在20fps下达到79.6％的竞争性mAP，或者在62fps下达到79.0％作为性能/速度折衷。

##### Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding

可读性：★

关键词：行人再识别

摘要：在本文中，我们通过竞争性片段相似性聚合和共同细分的片段嵌入来**解决基于视频的行人再识别问题**。我们的方法将长时间序列分成多个短视频片段，并聚合序列相似性估计的排名最高的片段相似度。采用这种策略，每个样本的人内视觉变化可以被最小化以进行相似性估计，同时保持多样的外观和时间信息。片段相似性通过深度神经网络进行估计，其中片段嵌入具有新颖的时间共同注意力。注意权重是基于查询特征获得的，该特征是通过LSTM网络从整个探测片段中学习的，使得产生的嵌入较少受到噪声帧的影响。图库片段与探针片段共享相同的查询功能。因此，图库片段的嵌入可以呈现更多相关特征以与探针片段进行比较，从而产生更准确的片段相似性。广泛的消融研究验证了竞争性片段相似性聚合的有效性以及时间共注意嵌入。我们的方法在多个数据集上显着优于当前最先进的方法。

##### Fast and Accurate Online Video Object Segmentation via Tracking Parts

可读性：★★★

关键词：视频目标分割

摘要：在线视频目标分割是一项具有挑战性的任务，因为它需要及时和准确地处理图像序列。为了通过视频分割目标对象，已经开发了许多基于CNN的方法，通过在第一帧中严格调整对象掩模，这对于在线应用来说是耗时的。在本文中，我们提出了一种快速准确的视频对象分割算法，一旦接收图像就可以立即开始分割过程。我们首先利用基于部位的跟踪方法来处理具有挑战性的因素，例如大变形，遮挡和混乱的背景。基于跟踪的部位边界框，我们构建了一个感兴趣区域分割网络来生成部位掩模。最后，通过将这些目标部位与第一帧中的视觉信息进行比较，采用基于相似性的评分函数来细化这些目标部位。我们的方法在DAVIS基准数据集的准确性上优于最先进的算法，同时实现更快的运行时性能。

代码：[FAVOS](https://github.com/JingchunCheng/FAVOS)

##### Context-aware Deep Feature Compression for High-speed Visual Tracking

可读性：★★★★★

关键词：目标跟踪，高速

摘要：我们提出了一种新的基于上下文感知的相关滤波器跟踪框架，以实现实时跟踪器之间的高计算速度和最先进的性能。对高计算速度的主要贡献在于所提出的**深度特征压缩**，其通过利用多个专家自动编码器的情境感知方案来实现;我们框架中的上下文是指根据外观模式的跟踪目标的粗略类别。在预训练阶段，每个类别训练一个专家自动编码器。在跟踪阶段，为给定目标选择最佳专家自动编码器，并且仅使用该自动编码器。为了实现压缩特征映射的高跟踪性能，我们引入了外部去噪过程和新的正交性损失项，用于专家自动编码器的预训练和微调。我们通过大量实验来验证所提出的情景感知框架，在这些实验中，我们的方法达到了与不能实时运行的最先进跟踪器相当的性能，同时以超过100 fps的极快速度运行。

项目：[traca-project](https://sites.google.com/site/jwchoivision/home/traca)

##### Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification

可读性：★★★

关键词：行人再识别

摘要：在一个域上训练的行人再识别模型通常不能很好地概括到另一个域。在我们的尝试中，我们提出了一个“通过翻译学习”的框架。在基线中，我们以无监督的方式将标记图像从源域转换为目标域。然后，我们通过监督方法对翻译后的图像进行训练。然而，作为该框架的重要组成部分，无监督图像图像转换在翻译过程中遭受源域标签的信息丢失。我们的动机是双重的。首先，对于每张图片，其ID标签中包含的区分线索应在翻译后保留。其次，考虑到两个领域完全不同的人的事实，翻译后的图片应该与任何目标ID不相同。为此，我们建议保留两种类型的无监督相似性，1）翻译前后的图像的自相似性，以及2）翻译后的源图像和目标图像的域不相似性。这两个约束条件都是在由连体网络和CycleGAN组成的相似性保持生成对抗网络（SPGAN）中实现的。通过域适应实验，我们发现由SPGAN产生的图像更适合于域适应，并且在两个大规模数据集上产生一致且有竞争力的行人再识别准确性。

##### Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification

可读性：★★★

关键词：行人再识别

摘要：在一个域上训练的行人再识别模型通常不能很好地概括到另一个域。在我们的尝试中，我们提出了一个“通过翻译学习”的框架。在基线中，我们以无监督的方式将标记图像从源域转换为目标域。然后，我们通过监督方法对翻译后的图像进行训练。然而，作为该框架的重要组成部分，无监督图像图像转换在翻译过程中遭受源域标签的信息丢失。我们的动机是双重的。首先，对于每张图片，其ID标签中包含的区分线索应在翻译后保留。其次，考虑到两个领域完全不同的人的事实，翻译后的图片应该与任何目标ID不相同。为此，我们建议保留两种类型的无监督相似性，1）翻译前后的图像的自相似性，以及2）翻译后的源图像和目标图像的域不相似性。这两个约束条件都是在由连体网络和CycleGAN组成的相似性保持生成对抗网络（SPGAN）中实现的。通过域适应实验，我们发现由SPGAN产生的图像更适合于域适应，并且在两个大规模数据集上产生一致且有竞争力的行人再识别准确性。

项目：[traca-project](https://sites.google.com/site/jwchoivision/home/traca)